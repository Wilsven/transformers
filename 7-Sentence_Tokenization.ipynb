{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_file = \"data/english.txt\"\n",
    "kannada_file = \"data/kannada.txt\"\n",
    "\n",
    "START_TOKEN = \"\"\n",
    "PADDING_TOKEN = \"\"\n",
    "END_TOKEN = \"\"\n",
    "\n",
    "kannada_vocabulary = [\n",
    "    START_TOKEN,\n",
    "    \" \",\n",
    "    \"!\",\n",
    "    '\"',\n",
    "    \"#\",\n",
    "    \"$\",\n",
    "    \"%\",\n",
    "    \"&\",\n",
    "    \"'\",\n",
    "    \"(\",\n",
    "    \")\",\n",
    "    \"*\",\n",
    "    \"+\",\n",
    "    \",\",\n",
    "    \"-\",\n",
    "    \".\",\n",
    "    \"/\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \":\",\n",
    "    \"<\",\n",
    "    \"=\",\n",
    "    \">\",\n",
    "    \"?\",\n",
    "    \"ˌ\",\n",
    "    \"ँ\",\n",
    "    \"ఆ\",\n",
    "    \"ఇ\",\n",
    "    \"ా\",\n",
    "    \"ి\",\n",
    "    \"ీ\",\n",
    "    \"ు\",\n",
    "    \"ూ\",\n",
    "    \"ಅ\",\n",
    "    \"ಆ\",\n",
    "    \"ಇ\",\n",
    "    \"ಈ\",\n",
    "    \"ಉ\",\n",
    "    \"ಊ\",\n",
    "    \"ಋ\",\n",
    "    \"ೠ\",\n",
    "    \"ಌ\",\n",
    "    \"ಎ\",\n",
    "    \"ಏ\",\n",
    "    \"ಐ\",\n",
    "    \"ಒ\",\n",
    "    \"ಓ\",\n",
    "    \"ಔ\",\n",
    "    \"ಕ\",\n",
    "    \"ಖ\",\n",
    "    \"ಗ\",\n",
    "    \"ಘ\",\n",
    "    \"ಙ\",\n",
    "    \"ಚ\",\n",
    "    \"ಛ\",\n",
    "    \"ಜ\",\n",
    "    \"ಝ\",\n",
    "    \"ಞ\",\n",
    "    \"ಟ\",\n",
    "    \"ಠ\",\n",
    "    \"ಡ\",\n",
    "    \"ಢ\",\n",
    "    \"ಣ\",\n",
    "    \"ತ\",\n",
    "    \"ಥ\",\n",
    "    \"ದ\",\n",
    "    \"ಧ\",\n",
    "    \"ನ\",\n",
    "    \"ಪ\",\n",
    "    \"ಫ\",\n",
    "    \"ಬ\",\n",
    "    \"ಭ\",\n",
    "    \"ಮ\",\n",
    "    \"ಯ\",\n",
    "    \"ರ\",\n",
    "    \"ಱ\",\n",
    "    \"ಲ\",\n",
    "    \"ಳ\",\n",
    "    \"ವ\",\n",
    "    \"ಶ\",\n",
    "    \"ಷ\",\n",
    "    \"ಸ\",\n",
    "    \"ಹ\",\n",
    "    \"಼\",\n",
    "    \"ಽ\",\n",
    "    \"ಾ\",\n",
    "    \"ಿ\",\n",
    "    \"ೀ\",\n",
    "    \"ು\",\n",
    "    \"ೂ\",\n",
    "    \"ೃ\",\n",
    "    \"ೄ\",\n",
    "    \"ೆ\",\n",
    "    \"ೇ\",\n",
    "    \"ೈ\",\n",
    "    \"ೊ\",\n",
    "    \"ೋ\",\n",
    "    \"ೌ\",\n",
    "    \"್\",\n",
    "    \"ೕ\",\n",
    "    \"ೖ\",\n",
    "    \"ೞ\",\n",
    "    \"ೣ\",\n",
    "    \"ಂ\",\n",
    "    \"ಃ\",\n",
    "    \"೦\",\n",
    "    \"೧\",\n",
    "    \"೨\",\n",
    "    \"೩\",\n",
    "    \"೪\",\n",
    "    \"೫\",\n",
    "    \"೬\",\n",
    "    \"೭\",\n",
    "    \"೮\",\n",
    "    \"೯\",\n",
    "    PADDING_TOKEN,\n",
    "    END_TOKEN,\n",
    "]\n",
    "\n",
    "english_vocabulary = [\n",
    "    START_TOKEN,\n",
    "    \" \",\n",
    "    \"!\",\n",
    "    '\"',\n",
    "    \"#\",\n",
    "    \"$\",\n",
    "    \"%\",\n",
    "    \"&\",\n",
    "    \"'\",\n",
    "    \"(\",\n",
    "    \")\",\n",
    "    \"*\",\n",
    "    \"+\",\n",
    "    \",\",\n",
    "    \"-\",\n",
    "    \".\",\n",
    "    \"/\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \":\",\n",
    "    \"<\",\n",
    "    \"=\",\n",
    "    \">\",\n",
    "    \"?\",\n",
    "    \"@\",\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"I\",\n",
    "    \"J\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"U\",\n",
    "    \"V\",\n",
    "    \"W\",\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"[\",\n",
    "    \"\\\\\",\n",
    "    \"]\",\n",
    "    \"^\",\n",
    "    \"_\",\n",
    "    \"`\",\n",
    "    \"a\",\n",
    "    \"b\",\n",
    "    \"c\",\n",
    "    \"d\",\n",
    "    \"e\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"h\",\n",
    "    \"i\",\n",
    "    \"j\",\n",
    "    \"k\",\n",
    "    \"l\",\n",
    "    \"m\",\n",
    "    \"n\",\n",
    "    \"o\",\n",
    "    \"p\",\n",
    "    \"q\",\n",
    "    \"r\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"u\",\n",
    "    \"v\",\n",
    "    \"w\",\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"z\",\n",
    "    \"{\",\n",
    "    \"|\",\n",
    "    \"}\",\n",
    "    \"~\",\n",
    "    PADDING_TOKEN,\n",
    "    END_TOKEN,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ಕ', 'ನ', '್', 'ನ', 'ಡ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"ಕನ್ನಡ\"\n",
    "list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ಕಾ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ಕ\" + \"ಾ\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every one of the English and Kannada vocabulary, we want to create an index. That's a dictionary that maps an integer to a character or a character that maps to an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_english = {k: v for k, v in enumerate(english_vocabulary)}\n",
    "index_to_kannada = {k: v for k, v in enumerate(kannada_vocabulary)}\n",
    "english_to_index = {v: k for k, v in enumerate(english_vocabulary)}\n",
    "kannada_to_index = {v: k for k, v in enumerate(kannada_vocabulary)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to read the files in the data folder and retrieve the top 100,000 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "with open(english_file, \"r\") as file:\n",
    "    english_sentences = file.readlines()\n",
    "with open(kannada_file, \"r\") as file:\n",
    "    kannada_sentences = file.readlines()\n",
    "\n",
    "# Limit number of sentences\n",
    "TOTAL_SENTENCES = 100000\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
    "# Remove any whitespaces or newline characters from left and right of sentences\n",
    "english_sentences = [sentence.strip() for sentence in english_sentences]\n",
    "kannada_sentences = [sentence.strip() for sentence in kannada_sentences]\n",
    "\n",
    "print(len(english_sentences))\n",
    "print(len(kannada_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hes a scientist.',\n",
       " \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
       " '8 lakh crore have been looted.',\n",
       " 'I read a lot into this as well.',\n",
       " \"She was found dead with the phone's battery exploded close to her head the following morning.\",\n",
       " 'How did mankind come under Satans rival sovereignty?',\n",
       " 'And then I became Prime Minister.',\n",
       " 'What about corruption?',\n",
       " 'No differences',\n",
       " '\"\"\"The shooting of the film is 90 percent done.\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.',\n",
       " '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"',\n",
       " 'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.',\n",
       " 'ಇದರ ಬಗ್ಗೆ ನಾನೂ ಸಾಕಷ್ಟು ಓದಿದ್ದೇನೆ.',\n",
       " 'ಆಕೆಯ ತಲೆಯ ಹತ್ತಿರ ಇರಿಸಿಕೊಂಡಿದ್ದ ಫೋನ್\\u200cನ ಬ್ಯಾಟರಿ ಸ್ಫೋಟಗೊಂಡು ಆಕೆ ಮೃತಪಟ್ಟಿದ್ದಾಳೆ ಎನ್ನಲಾಗಿದೆ.',\n",
       " 'ಮಾನವಕುಲವು ಸೈತಾನನ ಆಳಿಕೆಯ ಕೆಳಗೆ ಬಂದದ್ದು ಹೇಗೆ?',\n",
       " 'ನಂತರ ಪ್ರಧಾನಿ ಕೂಡ ಆಗುತ್ತೇನೆ.',\n",
       " 'ಭ್ರಷ್ಟಾಚಾರ ಏಕಿದೆ?',\n",
       " '‘ಅನುಪಾತದಲ್ಲಿ ವ್ಯತ್ಯಾಸವಿಲ್ಲ’',\n",
       " 'ಆ ಚಿತ್ರದ ಶೇ 90ರಷ್ಟು ಚಿತ್ರೀಕರಣವೂ ಈಗಾಗಲೇ ಮುಗಿದು ಹೋಗಿದೆ.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 639)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(sentence) for sentence in english_sentences), max(\n",
    "    len(sentence) for sentence in kannada_sentences\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Processing Sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer-architecture.png\" width=\"500\">\n",
    "\n",
    "As an input to this transformer neural network, we're going to convert every single character into some embedding instead of every single word as explained in previous sections. When we encode every character into an embedding, we want it to ideally be a little smaller so that there is not too many parameters to learn and inference becomes faster.\n",
    "\n",
    "From the output above, we can see that the longest sentence for English and Kannada are 722 and 639 respectively. We can plot a distribution of the length of the sentences in both languages and we can be fairly confident that the distribution will be right-skewed — meaning there are only a couple of sentences that are really long. In that sense, we can choose not to accomodate to those sentences that are super long (there's only a few of them anyways). It wouls make sense to simply accomodate to the majority and decrease the dimension so that it becomes easier to learn less parameters throughout the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/8AAAGHCAYAAADm7OLTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlE0lEQVR4nO3deViV1fr/8c+WSUDcIgpIopIiiTilpWilhoIDmk1mFEfL1HIKk6OZndIGzbnBrPSYmFrUyfSYA6E5lEdwIDnONplogZgiOILC8/ujL8+vLWqK4JZ93q/r2tfVXuvea93PXlDdrGewGIZhCAAAAAAAOKxK9k4AAAAAAACUL4p/AAAAAAAcHMU/AAAAAAAOjuIfAAAAAAAHR/EPAAAAAICDo/gHAAAAAMDBUfwDAAAAAODgKP4BAAAAAHBwFP8AAAAAADg4in8AgCkhIUEWi8V8Va5cWf7+/urYsaMmTpyo7OzsEp8ZN26cLBbLNc1z5swZjRs3TuvXr7+mz11qrnr16ik6OvqaxvkrH3/8sd58881L9lksFo0bN65M5ytrX3/9tVq1aiVPT09ZLBYtXbr0knG//fabxo0bp/T09BJ9/fr1U5UqVco3UZXu56c8rVy58rLra7FYNHTo0HLP4ZdfflH37t1VvXp1WSwWxcXFlfuc12LTpk0aN26cTpw4Ye9UAADXgOIfAFDCvHnzlJKSotWrV+vdd99V8+bNNWnSJDVq1Ehr1qyxiX3qqaeUkpJyTeOfOXNG48ePv+bivzRzlcaViv+UlBQ99dRT5Z5DaRmGod69e8vFxUXLli1TSkqK2rdvf8nY3377TePHj79k8f+/auXKlRo/frxdcxgxYoQ2b96sDz/8UCkpKRoxYoRd87nYpk2bNH78eIp/AKhgnO2dAADg5hMWFqZWrVqZ7x988EGNGDFCd911lx544AH98MMP8vPzkyTVrl1btWvXLtd8zpw5Iw8Pjxsy119p06aNXef/K7/99puOHz+u+++/XxEREfZOB6Wwa9cu3XnnnerVq5e9UwEAOBB2/gEAV6VOnTqaNm2aTp48qQ8++MBsv9Rp22vXrlWHDh3k4+Mjd3d31alTRw8++KDOnDmjX375RTVr1pQkjR8/3rzEoF+/fjbjfffdd3rooYfk7e2t+vXrX3auYkuWLFHTpk1VuXJl3XrrrXr77bdt+osvafjll19s2tevXy+LxWKehdChQwetWLFCBw8etLkEotilTvvftWuX7rvvPnl7e6ty5cpq3ry55s+ff8l5PvnkE40dO1YBAQGqWrWqOnXqpP3791/+i/+TjRs3KiIiQl5eXvLw8FDbtm21YsUKs3/cuHHmH0dGjx4ti8WievXqXXKs9evX64477pAkPfHEE+ZxXnxsP/74o7p166YqVaooMDBQI0eOVH5+vk1MQUGBXnvtNd12221yc3NTzZo19cQTT+jo0aNXdVyX8umnnyo8PFyenp6qUqWKoqKitH37dpuY4ksTribHw4cP66GHHpKXl5eqVaumxx57TFu3bpXFYlFCQoI53rvvvitJNmt/8c/MggUL1KhRI3l4eKhZs2Zavnz5VR1TRkaGHn/8cfn6+srNzU2NGjXStGnTVFRUJOn//4z8+OOPWrVq1WXn/7N//etfat26taxWqzw8PHTrrbfqySeftInJy8tTfHy8goKC5OrqqltuuUVxcXE6ffq0TVzxZQ1XOr5x48bp73//uyQpKCjIzPHPZ/GU9drl5+frlVdeUaNGjVS5cmX5+PioY8eO2rRpkxljGIZmzZql5s2by93dXd7e3nrooYf0888/24y1fft2RUdHm2sQEBCg7t276/Dhw5f9jgHAUVD8AwCuWrdu3eTk5KRvvvnmsjHF1yu7urrqww8/VFJSkt544w15enqqoKBAtWrVUlJSkiSpf//+SklJUUpKiv7xj3/YjPPAAw+oQYMG+te//qX333//inmlp6crLi5OI0aM0JIlS9S2bVs9++yzmjp16jUf46xZs9SuXTv5+/ubuV3pUoP9+/erbdu22r17t95++2198cUXCg0NVb9+/TR58uQS8S+88IIOHjyof/7zn5o9e7Z++OEH9ejRQ4WFhVfMa8OGDbr33nuVm5uruXPn6pNPPpGXl5d69OihTz/9VNIfl0V88cUXkqRhw4YpJSVFS5YsueR4t99+u+bNmydJevHFF83j/PMlDefPn1fPnj0VERGhf//733ryySc1Y8YMTZo0yYwpKirSfffdpzfeeEMxMTFasWKF3njjDa1evVodOnTQ2bNnr3hclzJhwgQ9+uijCg0N1WeffaYFCxbo5MmTuvvuu7Vnzx6b2KvJ8fTp0+rYsaPWrVunSZMm6bPPPpOfn58eeeQRm7H+8Y9/6KGHHpIkm7WvVauWGbNixQrNnDlTr7zyihYvXqzq1avr/vvvL1FkXuzo0aNq27atkpOT9eqrr2rZsmXq1KmT4uPjzfsI3H777UpJSZG/v7/atWt3yfn/LCUlRY888ohuvfVWJSYmasWKFXrppZd04cIFM+bMmTNq37695s+fr+HDh2vVqlUaPXq0EhIS1LNnTxmGYTPmXx3fU089pWHDhkmSvvjiCzPH22+/vVzW7sKFC+ratateffVVRUdHa8mSJUpISFDbtm2VkZFhxg0aNEhxcXHq1KmTli5dqlmzZmn37t1q27atjhw5Yv4cdO7cWUeOHNG7776r1atX680331SdOnV08uTJK64fADgEAwCA/zNv3jxDkrF169bLxvj5+RmNGjUy37/88svGn/9z8vnnnxuSjPT09MuOcfToUUOS8fLLL5foKx7vpZdeumzfn9WtW9ewWCwl5uvcubNRtWpV4/Tp0zbHduDAAZu4devWGZKMdevWmW3du3c36tate8ncL867T58+hpubm5GRkWET17VrV8PDw8M4ceKEzTzdunWzifvss88MSUZKSsol5yvWpk0bw9fX1zh58qTZduHCBSMsLMyoXbu2UVRUZBiGYRw4cMCQZEyZMuWK4xmGYWzdutWQZMybN69EX9++fQ1JxmeffWbT3q1bNyMkJMR8/8knnxiSjMWLF19y7FmzZl0xh4vXNCMjw3B2djaGDRtmE3fy5EnD39/f6N279zXn+O677xqSjFWrVtnEDRo0qMTxDxkypMTPWDFJhp+fn5GXl2e2ZWVlGZUqVTImTpx4xeN8/vnnDUnG5s2bbdqfeeYZw2KxGPv37zfb6tata3Tv3v2K4xmGYUydOtWQZP6MXcrEiRONSpUqlfidLv49Xbly5TUf35QpUy75u1Qea/fRRx8Zkow5c+Zc9hhTUlIMSca0adNs2g8dOmS4u7sbo0aNMgzDMLZt22ZIMpYuXXrZsQDAkbHzDwC4JsZFO4UXa968uVxdXTVw4EDNnz//L3dEL+fBBx+86tjGjRurWbNmNm0xMTHKy8vTd999V6r5r9batWsVERGhwMBAm/Z+/frpzJkzJc4a6Nmzp837pk2bSpIOHjx42TlOnz6tzZs366GHHrK5A7+Tk5NiY2N1+PDhq7504FpYLBb16NGjRL5/znX58uWqVq2aevTooQsXLpiv5s2by9/f/5pv6vjVV1/pwoUL+tvf/mYzXuXKldW+ffsS411Njhs2bJCXl5e6dOliE/foo49eU26S1LFjR3l5eZnv/fz85Ovre8X1k/74OQkNDdWdd95p096vXz8ZhqG1a9decy7Fl2307t1bn332mX799dcSMcuXL1dYWJiaN29u831GRUWVOF3/eo5PKp+1W7VqlSpXrlziUoaLj9Fisejxxx+3mdff31/NmjUz523QoIG8vb01evRovf/++yXORAAAR0fxDwC4aqdPn9axY8cUEBBw2Zj69etrzZo18vX11ZAhQ1S/fn3Vr19fb7311jXNdblTnS/F39//sm3Hjh27pnmv1bFjxy6Za/F3dPH8Pj4+Nu/d3Nwk6Yqnx+fk5MgwjGuapyx4eHiocuXKNm1ubm46d+6c+f7IkSM6ceKEXF1d5eLiYvPKysrS77//fk1zFp+ifccdd5QY79NPPy0x3tXkeOzYMfMGlX92qba/cvH6Fc/3V5c3XOvPydW45557tHTpUrPgrl27tsLCwvTJJ5+YMUeOHNGOHTtKfJdeXl4yDKPE91na4yueSyrbtTt69KgCAgJUqdLl/5f1yJEjMgxDfn5+JeZNTU0157VardqwYYOaN2+uF154QY0bN1ZAQIBefvllnT9//i+PDwAqOu72DwC4aitWrFBhYaE6dOhwxbi7775bd999twoLC7Vt2za98847iouLk5+fn/r06XNVc13Ls9+zsrIu21ZczBQXGRffTOxai9OL+fj4KDMzs0T7b7/9JkmqUaPGdY0vSd7e3qpUqVK5z1MaNWrUkI+Pj3kfh4v9eRf5aseTpM8//1x169a97vykP9Zoy5YtJdov9XNTXsrr5+S+++7Tfffdp/z8fKWmpmrixImKiYlRvXr1FB4erho1asjd3V0ffvjhJT9flj835bF2NWvW1MaNG1VUVHTZPwDUqFFDFotF3377rfnHtD/7c1uTJk2UmJgowzC0Y8cOJSQk6JVXXpG7u7uef/75MskZAG5W7PwDAK5KRkaG4uPjZbVaNWjQoKv6jJOTk1q3bm3eQb34FPyr2e2+Frt379Z///tfm7aPP/5YXl5e5o3Iiu96v2PHDpu4ZcuWlRjvanc6JSkiIkJr1641i7hiH330kTw8PMrk0YCenp5q3bq1vvjiC5u8ioqKtHDhQtWuXVsNGza85nHLYh2io6N17NgxFRYWqlWrViVeISEh1zReVFSUnJ2d9dNPP11yvD8/gvJqtW/fXidPntSqVats2hMTE0vElvXPZrGIiAjt2bOnxGUoH330kSwWizp27Hhd47u5ual9+/bmzfKK764fHR2tn376ST4+Ppf8Li/3NIi/mksq+R2Vx9p17dpV586dM5/IcCnR0dEyDEO//vrrJeds0qRJic9YLBY1a9ZMM2bMULVq1cr98iAAuBmw8w8AKGHXrl3mdbPZ2dn69ttvNW/ePDk5OWnJkiXmo/ou5f3339fatWvVvXt31alTR+fOnTN3HTt16iTpj93gunXr6t///rciIiJUvXp11ahRo1SFiPTHqdM9e/bUuHHjVKtWLS1cuFCrV6/WpEmT5OHhIemPU5FDQkIUHx+vCxcuyNvbW0uWLNHGjRtLjNekSRN98cUXeu+999SyZUtVqlTpsoXLyy+/rOXLl6tjx4566aWXVL16dS1atEgrVqzQ5MmTZbVaS3VMF5s4caI6d+6sjh07Kj4+Xq6urpo1a5Z27dqlTz755JrOlChWv359ubu7a9GiRWrUqJGqVKmigICAK17WcbE+ffpo0aJF6tatm5599lndeeedcnFx0eHDh7Vu3Trdd999uv/++696vHr16umVV17R2LFj9fPPP6tLly7y9vbWkSNHtGXLFnl6emr8+PHXdJx9+/bVjBkz9Pjjj+u1115TgwYNtGrVKn311VeSZLOjXFwoTpo0SV27dpWTk5OaNm0qV1fXa5rzYiNGjNBHH32k7t2765VXXlHdunW1YsUKzZo1S88880yp/njz0ksv6fDhw4qIiFDt2rV14sQJvfXWW3JxcVH79u0lSXFxcVq8eLHuuecejRgxQk2bNlVRUZEyMjKUnJyskSNHqnXr1tc0b/F39NZbb6lv375ycXFRSEhIuazdo48+qnnz5unpp5/W/v371bFjRxUVFWnz5s1q1KiR+vTpo3bt2mngwIF64okntG3bNt1zzz3y9PRUZmamNm7cqCZNmuiZZ57R8uXLNWvWLPXq1Uu33nqrDMPQF198oRMnTqhz587XlBcAVEj2u9cgAOBmU3xH/OKXq6ur4evra7Rv396YMGGCkZ2dXeIzF9+tPSUlxbj//vuNunXrGm5uboaPj4/Rvn17Y9myZTafW7NmjdGiRQvDzc3NkGT07dvXZryjR4/+5VyG8f/vjP75558bjRs3NlxdXY169eoZ06dPL/H577//3oiMjDSqVq1q1KxZ0xg2bJixYsWKEnf7P378uPHQQw8Z1apVMywWi82cusRTCnbu3Gn06NHDsFqthqurq9GsWbMSd9Avvtv/v/71L5v24rvzX+qO+xf79ttvjXvvvdfw9PQ03N3djTZt2hhffvnlJce7mrv9G8Yfd+u/7bbbDBcXF5tj69u3r+Hp6Vki/lJrcP78eWPq1KlGs2bNjMqVKxtVqlQxbrvtNmPQoEHGDz/8cMX5LzWeYRjG0qVLjY4dOxpVq1Y13NzcjLp16xoPPfSQsWbNGjPmWnLMyMgwHnjgAaNKlSqGl5eX8eCDDxorV640JBn//ve/zbj8/HzjqaeeMmrWrGmuffFd7SUZQ4YMKTFf3bp1zZ/fKzl48KARExNj+Pj4GC4uLkZISIgxZcoUo7CwsMR4V3O3/+XLlxtdu3Y1brnlFvN3tVu3bsa3335rE3fq1CnjxRdfNEJCQgxXV1fDarUaTZo0MUaMGGFkZWWZcddyfGPGjDECAgKMSpUqlfj9Keu1O3v2rPHSSy8ZwcHBhqurq+Hj42Pce++9xqZNm2ziPvzwQ6N169bm70f9+vWNv/3tb8a2bdsMwzCMffv2GY8++qhRv359w93d3bBarcadd95pJCQkXPmLBgAHYTGMv7htMwAAgAOaMGGCXnzxRWVkZKh27dr2TgcAgHLFaf8AAMDhzZw5U5J022236fz581q7dq3efvttPf744xT+AID/CRT/AADA4Xl4eGjGjBn65ZdflJ+frzp16mj06NF68cUX7Z0aAAA3BKf9AwAAAADg4HjUHwAAAAAADo7iHwAAAAAAB0fxDwAAAACAg+OGf2WoqKhIv/32m7y8vGSxWOydDgAAAADAwRmGoZMnTyogIECVKl1+f5/ivwz99ttvCgwMtHcaAAAAAID/MYcOHbri42sp/suQl5eXpD++9KpVq9o5GwAAAACAo8vLy1NgYKBZj14OxX8ZKj7Vv2rVqhT/AAAAAIAb5q8uPeeGfwAAAAAAODiKfwAAAAAAHBzFPwAAAAAADs6u1/xfuHBB48aN06JFi5SVlaVatWqpX79+evHFF81HFBiGofHjx2v27NnKyclR69at9e6776px48bmOPn5+YqPj9cnn3yis2fPKiIiQrNmzbK502FOTo6GDx+uZcuWSZJ69uypd955R9WqVTNjMjIyNGTIEK1du1bu7u6KiYnR1KlT5erqemO+EAAAAAAoZ4WFhTp//ry908BVcnJykrOz83U/Tt6uxf+kSZP0/vvva/78+WrcuLG2bdumJ554QlarVc8++6wkafLkyZo+fboSEhLUsGFDvfbaa+rcubP2799v3s0wLi5OX375pRITE+Xj46ORI0cqOjpaaWlpcnJykiTFxMTo8OHDSkpKkiQNHDhQsbGx+vLLLyX98QvQvXt31axZUxs3btSxY8fUt29fGYahd955xw7fDgAAAACUrVOnTunw4cMyDMPeqeAaeHh4qFatWte1MW0x7Ljq0dHR8vPz09y5c822Bx98UB4eHlqwYIEMw1BAQIDi4uI0evRoSX/s8vv5+WnSpEkaNGiQcnNzVbNmTS1YsECPPPKIJOm3335TYGCgVq5cqaioKO3du1ehoaFKTU1V69atJUmpqakKDw/Xvn37FBISolWrVik6OlqHDh1SQECAJCkxMVH9+vVTdnb2Vd29Py8vT1arVbm5udztHwAAAMBNpbCwUD/88IM8PDxUs2bN695JRvkzDEMFBQU6evSoCgsLFRwcbJ4lX+xq61C77vzfddddev/99/X999+rYcOG+u9//6uNGzfqzTfflCQdOHBAWVlZioyMND/j5uam9u3ba9OmTRo0aJDS0tJ0/vx5m5iAgACFhYVp06ZNioqKUkpKiqxWq1n4S1KbNm1ktVq1adMmhYSEKCUlRWFhYWbhL0lRUVHKz89XWlqaOnbsWCL//Px85efnm+/z8vLK8usBAAAAgDJz/vx5GYahmjVryt3d3d7p4Cq5u7vLxcVFBw8eVEFBgSpXrlyqcexa/I8ePVq5ubm67bbb5OTkpMLCQr3++ut69NFHJUlZWVmSJD8/P5vP+fn56eDBg2aMq6urvL29S8QUfz4rK0u+vr4l5vf19bWJuXgeb29vubq6mjEXmzhxosaPH3+thw0AAAAAdsOOf8Vz8W5/qcYogzxK7dNPP9XChQv18ccf67vvvtP8+fM1depUzZ8/3ybu4h9OwzD+8gf24phLxZcm5s/GjBmj3Nxc83Xo0KEr5gQAAAAAgD3Ydef/73//u55//nn16dNHktSkSRMdPHhQEydOVN++feXv7y9J5pMAimVnZ5u79P7+/iooKFBOTo7N7n92drbatm1rxhw5cqTE/EePHrUZZ/PmzTb9OTk5On/+fIkzAoq5ubnJzc2ttIcPAAAAAMANYded/zNnzpQ4fcHJyUlFRUWSpKCgIPn7+2v16tVmf0FBgTZs2GAW9i1btpSLi4tNTGZmpnbt2mXGhIeHKzc3V1u2bDFjNm/erNzcXJuYXbt2KTMz04xJTk6Wm5ubWrZsWcZHDgAAAAC4WSQkJNg8Bn7cuHFq3rz5VX32WmLtya47/z169NDrr7+uOnXqqHHjxtq+fbumT5+uJ598UtIfp+HHxcVpwoQJCg4OVnBwsCZMmCAPDw/FxMRIkqxWq/r376+RI0fKx8dH1atXV3x8vJo0aaJOnTpJkho1aqQuXbpowIAB+uCDDyT98ai/6OhohYSESJIiIyMVGhqq2NhYTZkyRcePH1d8fLwGDBjgkHfun7H6e3un4FBGdG5o7xQAAACAUrnRtcG1/r9zv379SlwaLv1xg/biR7mXtfj4eA0bNqxcxrYXuxb/77zzjv7xj39o8ODBys7OVkBAgAYNGqSXXnrJjBk1apTOnj2rwYMHKycnR61bt1ZycrK8vLzMmBkzZsjZ2Vm9e/fW2bNnFRERoYSEBDk5OZkxixYt0vDhw82nAvTs2VMzZ840+52cnLRixQoNHjxY7dq1k7u7u2JiYjR16tQb8E0AAAAAAC6nS5cumjdvnk1beV6CXaVKFVWpUqXcxrcHu5727+XlpTfffFMHDx7U2bNn9dNPP+m1116Tq6urGWOxWDRu3DhlZmbq3Llz2rBhg8LCwmzGqVy5st555x0dO3ZMZ86c0ZdffqnAwECbmOrVq2vhwoXKy8tTXl6eFi5caHNahyTVqVNHy5cv15kzZ3Ts2DG98847XNMPAAAAAHbm5uYmf39/m1fxPd8sFov++c9/6v7775eHh4eCg4O1bNkym88vW7ZMwcHBcnd3V8eOHTV//nxZLBadOHHikvNdfCr/+vXrdeedd8rT01PVqlVTu3btzCfQFVuwYIHq1asnq9WqPn366OTJk2X6HVwvuxb/AAAAAABcr/Hjx6t3797asWOHunXrpscee0zHjx+XJP3yyy966KGH1KtXL6Wnp2vQoEEaO3bsVY994cIF9erVS+3bt9eOHTuUkpKigQMH2jwV7qefftLSpUu1fPlyLV++XBs2bNAbb7xR5sd5PSj+AQAAAAA3teXLl5un4he/Xn31VbO/X79+evTRR9WgQQNNmDBBp0+fNm/4/v777yskJERTpkxRSEiI+vTpo379+l313Hl5ecrNzVV0dLTq16+vRo0aqW/fvqpTp44ZU1RUpISEBIWFhenuu+9WbGysvv766zI7/rJg12v+AQAAAAD4Kx07dtR7771n01a9enXzn5s2bWr+s6enp7y8vJSdnS1J2r9/v+644w6bz955551XPXf16tXVr18/RUVFqXPnzurUqZN69+5t8zj6evXq2dyXrlatWub8Nwt2/gEAAAAANzVPT081aNDA5vXn4t/FxcUm3mKxmI+QNwzD5hT94rZrMW/ePKWkpKht27b69NNP1bBhQ6Wmpl7V/DcLin8AAAAAgMO67bbbtHXrVpu2bdu2XfM4LVq00JgxY7Rp0yaFhYXp448/LqsUbwiKfwAAAADATS0/P19ZWVk2r99///2qPjto0CDt27dPo0eP1vfff6/PPvtMCQkJklTijIBLOXDggMaMGaOUlBQdPHhQycnJ+v7779WoUaPrOaQbjmv+AQAAAOB/2IjODe2dwl9KSkqyucZekkJCQrRv376//GxQUJA+//xzjRw5Um+99ZbCw8M1duxYPfPMM1f1aHcPDw/t27dP8+fP17Fjx1SrVi0NHTpUgwYNKvXx2IPFuNaLHXBZeXl5slqtys3NVdWqVe2dzhXNWP29vVNwKBXhX5gAAAD433bu3DkdOHBAQUFBqly5sr3TsavXX39d77//vg4dOmTvVK7KldbuautQdv4BAAAAAA5t1qxZuuOOO+Tj46P//Oc/mjJlioYOHWrvtG4oin8AAAAAgEP74Ycf9Nprr+n48eOqU6eORo4cqTFjxtg7rRuK4h8AAAAA4NBmzJihGTNm2DsNu+Ju/wAAAAAAODiKfwAAAAAAHByn/f+PapMx294pVBipdQbaOwUAAAAAuC7s/AMAAAAA4OAo/gEAAAAAcHAU/wAAAAAAODiu+QcAAACA/2XrJt7Y+TqOubHz2dEvv/yioKAgbd++Xc2bN7drLuz8AwAAAABuWv369VOvXr1s2j7//HNVrlxZkydPtk9SFRA7/wAAAACACuOf//ynhgwZonfffVdPPfWUvdOpMNj5BwAAAABUCJMnT9bQoUP18ccfm4X/woUL1apVK3l5ecnf318xMTHKzs42P7N+/XpZLBZ9/fXXatWqlTw8PNS2bVvt37/fjBk3bpyaN2+uBQsWqF69erJarerTp49OnjxpxiQlJemuu+5StWrV5OPjo+joaP300082+W3ZskUtWrRQ5cqV1apVK23fvt2mv7CwUP3791dQUJDc3d0VEhKit956qzy+qhIo/gEAAAAAN73nn39er776qpYvX64HH3zQbC8oKNCrr76q//73v1q6dKkOHDigfv36lfj82LFjNW3aNG3btk3Ozs568sknbfp/+uknLV26VMuXL9fy5cu1YcMGvfHGG2b/6dOn9dxzz2nr1q36+uuvValSJd1///0qKioy+6OjoxUSEqK0tDSNGzdO8fHxNnMUFRWpdu3a+uyzz7Rnzx699NJLeuGFF/TZZ5+V4Td1aZz2DwAAAAC4qa1atUr//ve/9fXXX+vee++16ftzEX/rrbfq7bff1p133qlTp06pSpUqZt/rr7+u9u3bS/rjDwndu3fXuXPnVLlyZUl/FOYJCQny8vKSJMXGxurrr7/W66+/Lkk2f3CQpLlz58rX11d79uxRWFiYFi1apMLCQn344Yfy8PBQ48aNdfjwYT3zzDPmZ1xcXDR+/HjzfVBQkDZt2qTPPvtMvXv3Louv6rLY+QcAAAAA3NSaNm2qevXq6aWXXrI5FV+Stm/frvvuu09169aVl5eXOnToIEnKyMgoMUaxWrVqSZLN5QH16tUzC//imD/3//TTT4qJidGtt96qqlWrKigoyGaevXv3qlmzZvLw8DA/Ex4eXuJY3n//fbVq1Uo1a9ZUlSpVNGfOnBK5lgeKfwAAAADATe2WW27Rhg0blJmZqS5duph/ADh9+rQiIyNVpUoVLVy4UFu3btWSJUsk/XE5wJ+5uLiY/2yxWCTJPGX/4v7imD/39+jRQ8eOHdOcOXO0efNmbd682WYewzD+8jg+++wzjRgxQk8++aSSk5OVnp6uJ554okSu5YHiHwAAAABw06tTp442bNig7OxsRUZGKi8vT/v27dPvv/+uN954Q3fffbduu+02m936snLs2DHt3btXL774oiIiItSoUSPl5OTYxISGhuq///2vzp49a7alpqbaxHz77bdq27atBg8erBYtWqhBgwYlbhpYXij+AQAAAAAVQu3atbV+/XodO3ZMkZGRqlGjhlxdXfXOO+/o559/1rJly/Tqq6+W+bze3t7y8fHR7Nmz9eOPP2rt2rV67rnnbGJiYmJUqVIl9e/fX3v27NHKlSs1depUm5gGDRpo27Zt+uqrr/T999/rH//4h7Zu3Vrm+V6KXW/4V69ePR08eLBE++DBg/Xuu+/KMAyNHz9es2fPVk5Ojlq3bq13331XjRs3NmPz8/MVHx+vTz75RGfPnlVERIRmzZql2rVrmzE5OTkaPny4li1bJknq2bOn3nnnHVWrVs2MycjI0JAhQ7R27Vq5u7srJiZGU6dOlaura/l9AQAAAABgbx3H2DuDa1J8CUDHjh318MMPKyEhQS+88ILefvtt3X777Zo6dap69uxZpnNWqlRJiYmJGj58uMLCwhQSEqK3337bvL+AJFWpUkVffvmlnn76abVo0UKhoaGaNGmSzY0Cn376aaWnp+uRRx6RxWLRo48+qsGDB2vVqlVlmu+lWIyruTChnBw9elSFhYXm+127dqlz585at26dOnTooEmTJun1119XQkKCGjZsqNdee03ffPON9u/fb96I4ZlnntGXX36phIQE+fj4aOTIkTp+/LjS0tLk5OQkSeratasOHz6s2bNnS5IGDhyoevXq6csvv5T0x7MWmzdvrpo1a2ratGk6duyY+vbtqwceeEDvvPPOVR9PXl6erFarcnNzVbVq1bL6mspFytz4vw6CJCm1zsC/jBnRueENyAQAAAAovXPnzunAgQMKCgoy73CPiuFKa3e1dahdd/5r1qxp8/6NN95Q/fr11b59exmGoTfffFNjx47VAw88IEmaP3++/Pz89PHHH2vQoEHKzc3V3LlztWDBAnXq1EmStHDhQgUGBmrNmjWKiorS3r17lZSUpNTUVLVu3VqSNGfOHIWHh2v//v0KCQlRcnKy9uzZo0OHDikgIECSNG3aNPXr10+vv/76Zb/A/Px85efnm+/z8vLK/DsCAAAAAOB63TTX/BcUFGjhwoV68sknZbFYdODAAWVlZSkyMtKMcXNzU/v27bVp0yZJUlpams6fP28TExAQoLCwMDMmJSVFVqvVLPwlqU2bNrJarTYxYWFhZuEvSVFRUcrPz1daWtplc544caKsVqv5CgwMLJsvAwAAAACAMnTTFP9Lly7ViRMn1K9fP0lSVlaWJMnPz88mzs/Pz+zLysqSq6urvL29rxjj6+tbYj5fX1+bmIvn8fb2lqurqxlzKWPGjFFubq75OnTo0DUcMQAAAAAAN4ZdT/v/s7lz56pr1642u+/S/3/+YjHDMEq0XezimEvFlybmYm5ubnJzc7tiLgAAAAAA2NtNsfN/8OBBrVmzRk899ZTZ5u/vL0kldt6zs7PNXXp/f38VFBSUeL7ixTFHjhwpMefRo0dtYi6eJycnR+fPny9xRgAAAAAAVGR2vOc7Sqks1uymKP7nzZsnX19fde/e3WwLCgqSv7+/Vq9ebbYVFBRow4YNatu2rSSpZcuWcnFxsYnJzMzUrl27zJjw8HDl5uZqy5YtZszmzZuVm5trE7Nr1y5lZmaaMcnJyXJzc1PLli3L56ABAAAA4AYqfhpaQUGBnTPBtTpz5owkycXFpdRj2P20/6KiIs2bN099+/aVs/P/T8disSguLk4TJkxQcHCwgoODNWHCBHl4eCgmJkaSZLVa1b9/f40cOVI+Pj6qXr264uPj1aRJE/Pu/40aNVKXLl00YMAAffDBB5L+eNRfdHS0QkJCJEmRkZEKDQ1VbGyspkyZouPHjys+Pl4DBgy46R/ZBwAAAABXw9nZWR4eHjp69KhcXFxUqdJNsReMKzAMQ2fOnFF2draqVatm/gGnNOxe/K9Zs0YZGRl68sknS/SNGjVKZ8+e1eDBg5WTk6PWrVsrOTlZXl5eZsyMGTPk7Oys3r176+zZs4qIiFBCQoLNl7Jo0SINHz7cfCpAz549NXPmTLPfyclJK1as0ODBg9WuXTu5u7srJiZGU6dOLccjBwAAAIAbx2KxqFatWjpw4IAOHjxo73RwDapVq2ZeGl9aFoMLPspMXl6erFarcnNzb/ozBlLmxts7hQojtc7Av4wZ0bnhDcgEAAAAuH5FRUWc+l+BuLi4XHHH/2rrULvv/AMAAAAAbpxKlSqpcuXK9k4DNxgXeQAAAAAA4OAo/gEAAAAAcHAU/wAAAAAAODiKfwAAAAAAHBzFPwAAAAAADo7iHwAAAAAAB0fxDwAAAACAg6P4BwAAAADAwVH8AwAAAADg4Cj+AQAAAABwcBT/AAAAAAA4OIp/AAAAAAAcHMU/AAAAAAAOjuIfAAAAAAAHR/EPAAAAAICDo/gHAAAAAMDBUfwDAAAAAODgKP4BAAAAAHBwFP8AAAAAADg4in8AAAAAABwcxT8AAAAAAA6O4h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwMFR/AMAAAAA4ODsXvz/+uuvevzxx+Xj4yMPDw81b95caWlpZr9hGBo3bpwCAgLk7u6uDh06aPfu3TZj5Ofna9iwYapRo4Y8PT3Vs2dPHT582CYmJydHsbGxslqtslqtio2N1YkTJ2xiMjIy1KNHD3l6eqpGjRoaPny4CgoKyu3YAQAAAAC4Eexa/Ofk5Khdu3ZycXHRqlWrtGfPHk2bNk3VqlUzYyZPnqzp06dr5syZ2rp1q/z9/dW5c2edPHnSjImLi9OSJUuUmJiojRs36tSpU4qOjlZhYaEZExMTo/T0dCUlJSkpKUnp6emKjY01+wsLC9W9e3edPn1aGzduVGJiohYvXqyRI0fekO8CAAAAAIDyYjEMw7DX5M8//7z+85//6Ntvv71kv2EYCggIUFxcnEaPHi3pj11+Pz8/TZo0SYMGDVJubq5q1qypBQsW6JFHHpEk/fbbbwoMDNTKlSsVFRWlvXv3KjQ0VKmpqWrdurUkKTU1VeHh4dq3b59CQkK0atUqRUdH69ChQwoICJAkJSYmql+/fsrOzlbVqlX/8njy8vJktVqVm5t7VfH2lDI33t4pVBipdQb+ZcyIzg1vQCYAAAAAYOtq61C77vwvW7ZMrVq10sMPPyxfX1+1aNFCc+bMMfsPHDigrKwsRUZGmm1ubm5q3769Nm3aJElKS0vT+fPnbWICAgIUFhZmxqSkpMhqtZqFvyS1adNGVqvVJiYsLMws/CUpKipK+fn5Npch/Fl+fr7y8vJsXgAAAAAA3GzsWvz//PPPeu+99xQcHKyvvvpKTz/9tIYPH66PPvpIkpSVlSVJ8vPzs/mcn5+f2ZeVlSVXV1d5e3tfMcbX17fE/L6+vjYxF8/j7e0tV1dXM+ZiEydONO8hYLVaFRgYeK1fAQAAAAAA5c6uxX9RUZFuv/12TZgwQS1atNCgQYM0YMAAvffeezZxFovF5r1hGCXaLnZxzKXiSxPzZ2PGjFFubq75OnTo0BVzAgAAAADAHuxa/NeqVUuhoaE2bY0aNVJGRoYkyd/fX5JK7LxnZ2ebu/T+/v4qKChQTk7OFWOOHDlSYv6jR4/axFw8T05Ojs6fP1/ijIBibm5uqlq1qs0LAAAAAICbjV2L/3bt2mn//v02bd9//73q1q0rSQoKCpK/v79Wr15t9hcUFGjDhg1q27atJKlly5ZycXGxicnMzNSuXbvMmPDwcOXm5mrLli1mzObNm5Wbm2sTs2vXLmVmZpoxycnJcnNzU8uWLcv4yAEAAAAAuHGc7Tn5iBEj1LZtW02YMEG9e/fWli1bNHv2bM2ePVvSH6fhx8XFacKECQoODlZwcLAmTJggDw8PxcTESJKsVqv69++vkSNHysfHR9WrV1d8fLyaNGmiTp06SfrjbIIuXbpowIAB+uCDDyRJAwcOVHR0tEJCQiRJkZGRCg0NVWxsrKZMmaLjx48rPj5eAwYMYEcfAAAAAFCh2bX4v+OOO7RkyRKNGTNGr7zyioKCgvTmm2/qscceM2NGjRqls2fPavDgwcrJyVHr1q2VnJwsLy8vM2bGjBlydnZW7969dfbsWUVERCghIUFOTk5mzKJFizR8+HDzqQA9e/bUzJkzzX4nJyetWLFCgwcPVrt27eTu7q6YmBhNnTr1BnwTAAAAAACUH4thGIa9k3AUV/t8xZtBytx4e6dQYaTWGfiXMSM6N7wBmQAAAACArautQ+16zT8AAAAAACh/FP8AAAAAADg4in8AAAAAABwcxT8AAAAAAA6O4h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwMFR/AMAAAAA4OAo/gEAAAAAcHAU/wAAAAAAODiKfwAAAAAAHBzFPwAAAAAADo7iHwAAAAAAB0fxDwAAAACAg6P4BwAAAADAwVH8AwAAAADg4Cj+AQAAAABwcBT/AAAAAAA4OIp/AAAAAAAcHMU/AAAAAAAOjuIfAAAAAAAHR/EPAAAAAICDo/gHAAAAAMDBUfwDAAAAAODgKP4BAAAAAHBwFP8AAAAAADg4uxb/48aNk8VisXn5+/ub/YZhaNy4cQoICJC7u7s6dOig3bt324yRn5+vYcOGqUaNGvL09FTPnj11+PBhm5icnBzFxsbKarXKarUqNjZWJ06csInJyMhQjx495OnpqRo1amj48OEqKCgot2MHAAAAAOBGsfvOf+PGjZWZmWm+du7cafZNnjxZ06dP18yZM7V161b5+/urc+fOOnnypBkTFxenJUuWKDExURs3btSpU6cUHR2twsJCMyYmJkbp6elKSkpSUlKS0tPTFRsba/YXFhaqe/fuOn36tDZu3KjExEQtXrxYI0eOvDFfAgAAAAAA5cjZ7gk4O9vs9hczDENvvvmmxo4dqwceeECSNH/+fPn5+enjjz/WoEGDlJubq7lz52rBggXq1KmTJGnhwoUKDAzUmjVrFBUVpb179yopKUmpqalq3bq1JGnOnDkKDw/X/v37FRISouTkZO3Zs0eHDh1SQECAJGnatGnq16+fXn/9dVWtWvUGfRsAAAAAAJQ9u+/8//DDDwoICFBQUJD69Omjn3/+WZJ04MABZWVlKTIy0ox1c3NT+/bttWnTJklSWlqazp8/bxMTEBCgsLAwMyYlJUVWq9Us/CWpTZs2slqtNjFhYWFm4S9JUVFRys/PV1pa2mVzz8/PV15ens0LAAAAAICbjV2L/9atW+ujjz7SV199pTlz5igrK0tt27bVsWPHlJWVJUny8/Oz+Yyfn5/Zl5WVJVdXV3l7e18xxtfXt8Tcvr6+NjEXz+Pt7S1XV1cz5lImTpxo3kfAarUqMDDwGr8BAAAAAADKn12L/65du+rBBx9UkyZN1KlTJ61YsULSH6f3F7NYLDafMQyjRNvFLo65VHxpYi42ZswY5ebmmq9Dhw5dMS8AAAAAAOzB7qf9/5mnp6eaNGmiH374wbwPwMU779nZ2eYuvb+/vwoKCpSTk3PFmCNHjpSY6+jRozYxF8+Tk5Oj8+fPlzgj4M/c3NxUtWpVmxcAAAAAADebm6r4z8/P1969e1WrVi0FBQXJ399fq1evNvsLCgq0YcMGtW3bVpLUsmVLubi42MRkZmZq165dZkx4eLhyc3O1ZcsWM2bz5s3Kzc21idm1a5cyMzPNmOTkZLm5ually5bleswAAAAAAJQ3u97tPz4+Xj169FCdOnWUnZ2t1157TXl5eerbt68sFovi4uI0YcIEBQcHKzg4WBMmTJCHh4diYmIkSVarVf3799fIkSPl4+Oj6tWrKz4+3ryMQJIaNWqkLl26aMCAAfrggw8kSQMHDlR0dLRCQkIkSZGRkQoNDVVsbKymTJmi48ePKz4+XgMGDGA3HwAAAABQ4dm1+D98+LAeffRR/f7776pZs6batGmj1NRU1a1bV5I0atQonT17VoMHD1ZOTo5at26t5ORkeXl5mWPMmDFDzs7O6t27t86ePauIiAglJCTIycnJjFm0aJGGDx9uPhWgZ8+emjlzptnv5OSkFStWaPDgwWrXrp3c3d0VExOjqVOn3qBvAgAAAACA8mMxDMOwdxKOIi8vT1arVbm5uTf9GQMpc+PtnUKFkVpn4F/GjOjc8AZkAgAAAAC2rrYOvamu+QcAAAAAAGWP4h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwMGVqvj/7rvvtHPnTvP9v//9b/Xq1UsvvPCCCgoKyiw5AAAAAABw/UpV/A8aNEjff/+9JOnnn39Wnz595OHhoX/9618aNWpUmSYIAAAAAACuT6mK/++//17NmzeXJP3rX//SPffco48//lgJCQlavHhxWeYHAAAAAACuU6mKf8MwVFRUJElas2aNunXrJkkKDAzU77//XnbZAQAAAACA61aq4r9Vq1Z67bXXtGDBAm3YsEHdu3eXJB04cEB+fn5lmiAAAAAAALg+pSr+Z8yYoe+++05Dhw7V2LFj1aBBA0nS559/rrZt25ZpggAAAAAA4Po4l+ZDzZo1s7nbf7EpU6bI2blUQwIAAAAAgHJSqp3/W2+9VceOHSvRfu7cOTVs2PC6kwIAAAAAAGWnVMX/L7/8osLCwhLt+fn5Onz48HUnBQAAAAAAys41naO/bNky85+/+uorWa1W831hYaG+/vprBQUFlV12AAAAAADgul1T8d+rVy9JksViUd++fW36XFxcVK9ePU2bNq3MkgMAAAAAANfvmor/oqIiSVJQUJC2bt2qGjVqlEtSAAAAAACg7JTq1vwHDhwo6zwAAAAAAEA5KfVz+b7++mt9/fXXys7ONs8IKPbhhx9ed2IAAAAAAKBslKr4Hz9+vF555RW1atVKtWrVksViKeu8AAAAAABAGSlV8f/+++8rISFBsbGxZZ0PAAAAAAAoY5VK86GCggK1bdu2rHMBAAAAAADloFTF/1NPPaWPP/64rHMBAAAAAADloFSn/Z87d06zZ8/WmjVr1LRpU7m4uNj0T58+vUySAwAAAAAA169Uxf+OHTvUvHlzSdKuXbts+rj5HwAAAAAAN5dSFf/r1q0r6zwAAAAAAEA5KdU1/wAAAAAAoOIoVfHfsWNH3XvvvZd9lcbEiRNlsVgUFxdnthmGoXHjxikgIEDu7u7q0KGDdu/ebfO5/Px8DRs2TDVq1JCnp6d69uypw4cP28Tk5OQoNjZWVqtVVqtVsbGxOnHihE1MRkaGevToIU9PT9WoUUPDhw9XQUFBqY4FAAAAAICbSamK/+bNm6tZs2bmKzQ0VAUFBfruu+/UpEmTax5v69atmj17tpo2bWrTPnnyZE2fPl0zZ87U1q1b5e/vr86dO+vkyZNmTFxcnJYsWaLExERt3LhRp06dUnR0tAoLC82YmJgYpaenKykpSUlJSUpPT1dsbKzZX1hYqO7du+v06dPauHGjEhMTtXjxYo0cObIU3w4AAAAAADeXUl3zP2PGjEu2jxs3TqdOnbqmsU6dOqXHHntMc+bM0WuvvWa2G4ahN998U2PHjtUDDzwgSZo/f778/Pz08ccfa9CgQcrNzdXcuXO1YMECderUSZK0cOFCBQYGas2aNYqKitLevXuVlJSk1NRUtW7dWpI0Z84chYeHa//+/QoJCVFycrL27NmjQ4cOKSAgQJI0bdo09evXT6+//rqqVq16zd8RAAAAAAA3izK95v/xxx/Xhx9+eE2fGTJkiLp3724W78UOHDigrKwsRUZGmm1ubm5q3769Nm3aJElKS0vT+fPnbWICAgIUFhZmxqSkpMhqtZqFvyS1adNGVqvVJiYsLMws/CUpKipK+fn5SktLu2zu+fn5ysvLs3kBAAAAAHCzKdXO/+WkpKSocuXKVx2fmJio7777Tlu3bi3Rl5WVJUny8/Ozaffz89PBgwfNGFdXV3l7e5eIKf58VlaWfH19S4zv6+trE3PxPN7e3nJ1dTVjLmXixIkaP378Xx0mAAAAAAB2Variv/g0/GKGYSgzM1Pbtm3TP/7xj6sa49ChQ3r22WeVnJx8xT8YWCyWEnNd3Haxi2MuFV+amIuNGTNGzz33nPk+Ly9PgYGBV8wNAAAAAIAbrVTFv9VqtXlfqVIlhYSE6JVXXrE5Bf9K0tLSlJ2drZYtW5pthYWF+uabbzRz5kzt379f0h+78rVq1TJjsrOzzV16f39/FRQUKCcnx2b3Pzs7W23btjVjjhw5UmL+o0eP2oyzefNmm/6cnBydP3++xBkBf+bm5iY3N7erOl4AAAAAAOylVMX/vHnzrnviiIgI7dy506btiSee0G233abRo0fr1ltvlb+/v1avXq0WLVpIkgoKCrRhwwZNmjRJktSyZUu5uLho9erV6t27tyQpMzNTu3bt0uTJkyVJ4eHhys3N1ZYtW3TnnXdKkjZv3qzc3FzzDwTh4eF6/fXXlZmZaf6hITk5WW5ubjZ/nAAAAAAAoCK6rmv+09LStHfvXlksFoWGhppF+tXw8vJSWFiYTZunp6d8fHzM9ri4OE2YMEHBwcEKDg7WhAkT5OHhoZiYGEl/nIHQv39/jRw5Uj4+Pqpevbri4+PVpEkT8waCjRo1UpcuXTRgwAB98MEHkqSBAwcqOjpaISEhkqTIyEiFhoYqNjZWU6ZM0fHjxxUfH68BAwZwp38AAAAAQIVXquI/Oztbffr00fr161WtWjUZhqHc3Fx17NhRiYmJqlmzZpkkN2rUKJ09e1aDBw9WTk6OWrdureTkZHl5eZkxM2bMkLOzs3r37q2zZ88qIiJCCQkJcnJyMmMWLVqk4cOHm5ck9OzZUzNnzjT7nZyctGLFCg0ePFjt2rWTu7u7YmJiNHXq1DI5DgAAAAAA7MliGIZxrR965JFH9NNPP2nBggVq1KiRJGnPnj3q27evGjRooE8++aTME60I8vLyZLValZube9OfMZAyN97eKVQYqXUG/mXMiM4Nb0AmAAAAAGDrauvQUu38JyUlac2aNWbhL0mhoaF69913r/qGfwAAAAAA4MaoVJoPFRUVycXFpUS7i4uLioqKrjspAAAAAABQdkpV/N9777169tln9dtvv5ltv/76q0aMGKGIiIgySw4AAAAAAFy/UhX/M2fO1MmTJ1WvXj3Vr19fDRo0UFBQkE6ePKl33nmnrHMEAAAAAADXoVTX/AcGBuq7777T6tWrtW/fPhmGodDQUPPxegAAAAAA4OZxTTv/a9euVWhoqPLy8iRJnTt31rBhwzR8+HDdcccdaty4sb799ttySRQAAAAAAJTONRX/b775pgYMGHDJxwdYrVYNGjRI06dPL7PkAAAAAADA9bum4v+///2vunTpctn+yMhIpaWlXXdSAAAAAACg7FxT8X/kyJFLPuKvmLOzs44ePXrdSQEAAAAAgLJzTcX/Lbfcop07d162f8eOHapVq9Z1JwUAAAAAAMrONRX/3bp100svvaRz586V6Dt79qxefvllRUdHl1lyAAAAAADg+l3To/5efPFFffHFF2rYsKGGDh2qkJAQWSwW7d27V++++64KCws1duzY8soVAAAAAACUwjUV/35+ftq0aZOeeeYZjRkzRoZhSJIsFouioqI0a9Ys+fn5lUuiAAAAAACgdK6p+JekunXrauXKlcrJydGPP/4owzAUHBwsb2/v8sgPAAAAAABcp2su/ot5e3vrjjvuKMtcAAAAAABAObimG/4BAAAAAICKh+IfAAAAAAAHR/EPAAAAAICDo/gHAAAAAMDBUfwDAAAAAODgKP4BAAAAAHBwFP8AAAAAADg4in8AAAAAABwcxT8AAAAAAA6O4h8AAAAAAAdH8Q8AAAAAgIOza/H/3nvvqWnTpqpataqqVq2q8PBwrVq1yuw3DEPjxo1TQECA3N3d1aFDB+3evdtmjPz8fA0bNkw1atSQp6enevbsqcOHD9vE5OTkKDY2VlarVVarVbGxsTpx4oRNTEZGhnr06CFPT0/VqFFDw4cPV0FBQbkdOwAAAAAAN4pdi//atWvrjTfe0LZt27Rt2zbde++9uu+++8wCf/LkyZo+fbpmzpyprVu3yt/fX507d9bJkyfNMeLi4rRkyRIlJiZq48aNOnXqlKKjo1VYWGjGxMTEKD09XUlJSUpKSlJ6erpiY2PN/sLCQnXv3l2nT5/Wxo0blZiYqMWLF2vkyJE37ssAAAAAAKCcWAzDMOydxJ9Vr15dU6ZM0ZNPPqmAgADFxcVp9OjRkv7Y5ffz89OkSZM0aNAg5ebmqmbNmlqwYIEeeeQRSdJvv/2mwMBArVy5UlFRUdq7d69CQ0OVmpqq1q1bS5JSU1MVHh6uffv2KSQkRKtWrVJ0dLQOHTqkgIAASVJiYqL69eun7OxsVa1a9apyz8vLk9VqVW5u7lV/xl5S5sbbO4UKI7XOwL+MGdG54Q3IBAAAAABsXW0detNc819YWKjExESdPn1a4eHhOnDggLKyshQZGWnGuLm5qX379tq0aZMkKS0tTefPn7eJCQgIUFhYmBmTkpIiq9VqFv6S1KZNG1mtVpuYsLAws/CXpKioKOXn5ystLe2yOefn5ysvL8/mBQAAAADAzcbuxf/OnTtVpUoVubm56emnn9aSJUsUGhqqrKwsSZKfn59NvJ+fn9mXlZUlV1dXeXt7XzHG19e3xLy+vr42MRfP4+3tLVdXVzPmUiZOnGjeR8BqtSowMPAajx4AAAAAgPJn9+I/JCRE6enpSk1N1TPPPKO+fftqz549Zr/FYrGJNwyjRNvFLo65VHxpYi42ZswY5ebmmq9Dhw5dMS8AAAAAAOzB7sW/q6urGjRooFatWmnixIlq1qyZ3nrrLfn7+0tSiZ337Oxsc5fe399fBQUFysnJuWLMkSNHSsx79OhRm5iL58nJydH58+dLnBHwZ25ubuaTCopfAAAAAADcbOxe/F/MMAzl5+crKChI/v7+Wr16tdlXUFCgDRs2qG3btpKkli1bysXFxSYmMzNTu3btMmPCw8OVm5urLVu2mDGbN29Wbm6uTcyuXbuUmZlpxiQnJ8vNzU0tW7Ys1+MFAAAAAKC8Odtz8hdeeEFdu3ZVYGCgTp48qcTERK1fv15JSUmyWCyKi4vThAkTFBwcrODgYE2YMEEeHh6KiYmRJFmtVvXv318jR46Uj4+Pqlevrvj4eDVp0kSdOnWSJDVq1EhdunTRgAED9MEHH0iSBg4cqOjoaIWEhEiSIiMjFRoaqtjYWE2ZMkXHjx9XfHy8BgwYwG4+AAAAAKDCs2vxf+TIEcXGxiozM1NWq1VNmzZVUlKSOnfuLEkaNWqUzp49q8GDBysnJ0etW7dWcnKyvLy8zDFmzJghZ2dn9e7dW2fPnlVERIQSEhLk5ORkxixatEjDhw83nwrQs2dPzZw50+x3cnLSihUrNHjwYLVr107u7u6KiYnR1KlTb9A3AQAAAABA+bEYhmHYOwlHcbXPV7wZpMyNt3cKFUZqnYF/GTOic8MbkAkAAAAA2LraOvSmu+YfAAAAAACULYp/AAAAAAAcHMU/AAAAAAAOjuIfAAAAAAAHR/EPAAAAAICDo/gHAAAAAMDBUfwDAAAAAODgKP4BAAAAAHBwFP8AAAAAADg4in8AAAAAABwcxT8AAAAAAA6O4h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwMFR/AMAAAAA4OAo/gEAAAAAcHAU/wAAAAAAODiKfwAAAAAAHBzFPwAAAAAADo7iHwAAAAAAB0fxDwAAAACAg6P4BwAAAADAwVH8AwAAAADg4Cj+AQAAAABwcBT/AAAAAAA4OIp/AAAAAAAcnF2L/4kTJ+qOO+6Ql5eXfH191atXL+3fv98mxjAMjRs3TgEBAXJ3d1eHDh20e/dum5j8/HwNGzZMNWrUkKenp3r27KnDhw/bxOTk5Cg2NlZWq1VWq1WxsbE6ceKETUxGRoZ69OghT09P1ahRQ8OHD1dBQUG5HDsAAAAAADeKXYv/DRs2aMiQIUpNTdXq1at14cIFRUZG6vTp02bM5MmTNX36dM2cOVNbt26Vv7+/OnfurJMnT5oxcXFxWrJkiRITE7Vx40adOnVK0dHRKiwsNGNiYmKUnp6upKQkJSUlKT09XbGxsWZ/YWGhunfvrtOnT2vjxo1KTEzU4sWLNXLkyBvzZQAAAAAAUE4shmEY9k6i2NGjR+Xr66sNGzbonnvukWEYCggIUFxcnEaPHi3pj11+Pz8/TZo0SYMGDVJubq5q1qypBQsW6JFHHpEk/fbbbwoMDNTKlSsVFRWlvXv3KjQ0VKmpqWrdurUkKTU1VeHh4dq3b59CQkK0atUqRUdH69ChQwoICJAkJSYmql+/fsrOzlbVqlX/Mv+8vDxZrVbl5uZeVbw9pcyNt3cKFUZqnYF/GTOic8MbkAkAAAAA2LraOvSmuuY/NzdXklS9enVJ0oEDB5SVlaXIyEgzxs3NTe3bt9emTZskSWlpaTp//rxNTEBAgMLCwsyYlJQUWa1Ws/CXpDZt2shqtdrEhIWFmYW/JEVFRSk/P19paWmXzDc/P195eXk2LwAAAAAAbjY3TfFvGIaee+453XXXXQoLC5MkZWVlSZL8/PxsYv38/My+rKwsubq6ytvb+4oxvr6+Jeb09fW1ibl4Hm9vb7m6upoxF5s4caJ5DwGr1arAwMBrPWwAAAAAAMrdTVP8Dx06VDt27NAnn3xSos9isdi8NwyjRNvFLo65VHxpYv5szJgxys3NNV+HDh26Yk4AAAAAANjDTVH8Dxs2TMuWLdO6detUu3Zts93f31+SSuy8Z2dnm7v0/v7+KigoUE5OzhVjjhw5UmLeo0eP2sRcPE9OTo7Onz9f4oyAYm5ubqpatarNCwAAAACAm41di3/DMDR06FB98cUXWrt2rYKCgmz6g4KC5O/vr9WrV5ttBQUF2rBhg9q2bStJatmypVxcXGxiMjMztWvXLjMmPDxcubm52rJlixmzefNm5ebm2sTs2rVLmZmZZkxycrLc3NzUsmXLsj94AAAAAABuEGd7Tj5kyBB9/PHH+ve//y0vLy9z591qtcrd3V0Wi0VxcXGaMGGCgoODFRwcrAkTJsjDw0MxMTFmbP/+/TVy5Ej5+PioevXqio+PV5MmTdSpUydJUqNGjdSlSxcNGDBAH3zwgSRp4MCBio6OVkhIiCQpMjJSoaGhio2N1ZQpU3T8+HHFx8drwIAB7OgDAAAAACo0uxb/7733niSpQ4cONu3z5s1Tv379JEmjRo3S2bNnNXjwYOXk5Kh169ZKTk6Wl5eXGT9jxgw5Ozurd+/eOnv2rCIiIpSQkCAnJyczZtGiRRo+fLj5VICePXtq5syZZr+Tk5NWrFihwYMHq127dnJ3d1dMTIymTp1aTkcPAAAAAMCNYTEMw7B3Eo7iap+veDNImRtv7xQqjNQ6A/8yZkTnhjcgEwAAAACwdbV1qF13/oGKoE3G7L8OWudT/onc7DqOsXcGAAAAAC7jprjbPwAAAAAAKD8U/wAAAAAAODiKfwAAAAAAHBzFPwAAAAAADo7iHwAAAAAAB0fxDwAAAACAg6P4BwAAAADAwVH8AwAAAADg4Cj+AQAAAABwcM72TgBwBCk/H7N3CnaXeuH7Mh1vROeGZToeAAAA8L+MnX8AAAAAABwcxT8AAAAAAA6O4h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwMFR/AMAAAAA4OAo/gEAAAAAcHAU/wAAAAAAODiKfwAAAAAAHBzFPwAAAAAADo7iHwAAAAAAB0fxDwAAAACAg6P4BwAAAADAwVH8AwAAAADg4Cj+AQAAAABwcBT/AAAAAAA4OLsW/99884169OihgIAAWSwWLV261KbfMAyNGzdOAQEBcnd3V4cOHbR7926bmPz8fA0bNkw1atSQp6enevbsqcOHD9vE5OTkKDY2VlarVVarVbGxsTpx4oRNTEZGhnr06CFPT0/VqFFDw4cPV0FBQXkcNgAAAAAAN5Rdi//Tp0+rWbNmmjlz5iX7J0+erOnTp2vmzJnaunWr/P391blzZ508edKMiYuL05IlS5SYmKiNGzfq1KlTio6OVmFhoRkTExOj9PR0JSUlKSkpSenp6YqNjTX7CwsL1b17d50+fVobN25UYmKiFi9erJEjR5bfwQMAAAAAcINYDMMw7J2EJFksFi1ZskS9evWS9Meuf0BAgOLi4jR69GhJf+zy+/n5adKkSRo0aJByc3NVs2ZNLViwQI888ogk6bffflNgYKBWrlypqKgo7d27V6GhoUpNTVXr1q0lSampqQoPD9e+ffsUEhKiVatWKTo6WocOHVJAQIAkKTExUf369VN2draqVq16VceQl5cnq9Wq3Nzcq/6MvaTMjbd3CnAwqXUGlul4Izo3LNPxAAAAAEd0tXXoTXvN/4EDB5SVlaXIyEizzc3NTe3bt9emTZskSWlpaTp//rxNTEBAgMLCwsyYlJQUWa1Ws/CXpDZt2shqtdrEhIWFmYW/JEVFRSk/P19paWmXzTE/P195eXk2LwAAAAAAbjY3bfGflZUlSfLz87Np9/PzM/uysrLk6uoqb2/vK8b4+vqWGN/X19cm5uJ5vL295erqasZcysSJE837CFitVgUGBl7jUQIAAAAAUP5u2uK/mMVisXlvGEaJtotdHHOp+NLEXGzMmDHKzc01X4cOHbpiXgAAAAAA2MNNW/z7+/tLUomd9+zsbHOX3t/fXwUFBcrJyblizJEjR0qMf/ToUZuYi+fJycnR+fPnS5wR8Gdubm6qWrWqzQsAAAAAgJvNTVv8BwUFyd/fX6tXrzbbCgoKtGHDBrVt21aS1LJlS7m4uNjEZGZmateuXWZMeHi4cnNztWXLFjNm8+bNys3NtYnZtWuXMjMzzZjk5GS5ubmpZcuW5XqcAAAAAACUN2d7Tn7q1Cn9+OOP5vsDBw4oPT1d1atXV506dRQXF6cJEyYoODhYwcHBmjBhgjw8PBQTEyNJslqt6t+/v0aOHCkfHx9Vr15d8fHxatKkiTp16iRJatSokbp06aIBAwbogw8+kCQNHDhQ0dHRCgkJkSRFRkYqNDRUsbGxmjJlio4fP674+HgNGDCA3XwAAAAAQIVn1+J/27Zt6tixo/n+ueeekyT17dtXCQkJGjVqlM6ePavBgwcrJydHrVu3VnJysry8vMzPzJgxQ87Ozurdu7fOnj2riIgIJSQkyMnJyYxZtGiRhg8fbj4VoGfPnpo5c6bZ7+TkpBUrVmjw4MFq166d3N3dFRMTo6lTp5b3VwAAAAAAQLmzGIZh2DsJR3G1z1e8GaTMjbd3CnAwqXUGlul4Izo3LNPxAAAAAEd0tXXoTXvNPwAAAAAAKBsU/wAAAAAAODiKfwAAAAAAHBzFPwAAAAAADo7iHwAAAAAAB0fxDwAAAACAg6P4BwAAAADAwVH8AwAAAADg4Cj+AQAAAABwcBT/AAAAAAA4OGd7JwDAMbTJmF22A67zKdvxbiYdx9g7AwAAAPyPYecfAAAAAAAHR/EPAAAAAICDo/gHAAAAAMDBcc0/gJtSys/H7J1CuUm98L1d5h3RuaFd5gUAAID9sfMPAAAAAICDo/gHAAAAAMDBUfwDAAAAAODgKP4BAAAAAHBwFP8AAAAAADg4in8AAAAAABwcxT8AAAAAAA6O4h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwME52zsBAPhf0yZjtn0mXudjn3mvR8cx9s4AAADAIVD8X2TWrFmaMmWKMjMz1bhxY7355pu6++677Z0WAFy3lJ+P2TuFa5Z64Xt7p3BZIzo3tHcKAAAAV43T/v/k008/VVxcnMaOHavt27fr7rvvVteuXZWRkWHv1AAAAAAAKDWK/z+ZPn26+vfvr6eeekqNGjXSm2++qcDAQL333nv2Tg0AAAAAgFLjtP//U1BQoLS0ND3//PM27ZGRkdq0adMlP5Ofn6/8/HzzfW5uriQpLy+v/BItI6fP5v91EADYWZP979g7hctas9/eGTieO+tVL/9J7hlZ/nMAAHADFdefhmFcMY7i///8/vvvKiwslJ+fn027n5+fsrKyLvmZiRMnavz48SXaAwMDyyVHAABwvV6xdwIAAJSLkydPymq1Xraf4v8iFovF5r1hGCXaio0ZM0bPPfec+b6oqEjHjx+Xj4/PZT9zI+Xl5SkwMFCHDh1S1apV7Z0Oygjr6phYV8fEujom1tUxsa6OiXV1PKxpSYZh6OTJkwoICLhiHMX//6lRo4acnJxK7PJnZ2eXOBugmJubm9zc3GzaqlWrVl4pllrVqlX5xXBArKtjYl0dE+vqmFhXx8S6OibW1fGwprautONfjBv+/R9XV1e1bNlSq1evtmlfvXq12rZta6esAAAAAAC4fuz8/8lzzz2n2NhYtWrVSuHh4Zo9e7YyMjL09NNP2zs1AAAAAABKjeL/Tx555BEdO3ZMr7zyijIzMxUWFqaVK1eqbt269k6tVNzc3PTyyy+XuDQBFRvr6phYV8fEujom1tUxsa6OiXV1PKxp6VmMv3oeAAAAAAAAqNC45h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwMFR/AMAAAAA4OAo/h3UrFmzFBQUpMqVK6tly5b69ttv7Z0SruCbb75Rjx49FBAQIIvFoqVLl9r0G4ahcePGKSAgQO7u7urQoYN2795tE5Ofn69hw4apRo0a8vT0VM+ePXX48OEbeBS42MSJE3XHHXfIy8tLvr6+6tWrl/bv328Tw9pWPO+9956aNm2qqlWrqmrVqgoPD9eqVavMfta04ps4caIsFovi4uLMNta14hk3bpwsFovNy9/f3+xnTSuuX3/9VY8//rh8fHzk4eGh5s2bKy0tzexnbSueevXqlfh9tVgsGjJkiCTWtKxQ/DugTz/9VHFxcRo7dqy2b9+uu+++W127dlVGRoa9U8NlnD59Ws2aNdPMmTMv2T958mRNnz5dM2fO1NatW+Xv76/OnTvr5MmTZkxcXJyWLFmixMREbdy4UadOnVJ0dLQKCwtv1GHgIhs2bNCQIUOUmpqq1atX68KFC4qMjNTp06fNGNa24qldu7beeOMNbdu2Tdu2bdO9996r++67z/yfENa0Ytu6datmz56tpk2b2rSzrhVT48aNlZmZab527txp9rGmFVNOTo7atWsnFxcXrVq1Snv27NG0adNUrVo1M4a1rXi2bt1q87u6evVqSdLDDz8siTUtMwYczp133mk8/fTTNm233Xab8fzzz9spI1wLScaSJUvM90VFRYa/v7/xxhtvmG3nzp0zrFar8f777xuGYRgnTpwwXFxcjMTERDPm119/NSpVqmQkJSXdsNxxZdnZ2YYkY8OGDYZhsLaOxNvb2/jnP//JmlZwJ0+eNIKDg43Vq1cb7du3N5599lnDMPhdrahefvllo1mzZpfsY00rrtGjRxt33XXXZftZW8fw7LPPGvXr1zeKiopY0zLEzr+DKSgoUFpamiIjI23aIyMjtWnTJjtlhetx4MABZWVl2aypm5ub2rdvb65pWlqazp8/bxMTEBCgsLAw1v0mkpubK0mqXr26JNbWERQWFioxMVGnT59WeHg4a1rBDRkyRN27d1enTp1s2lnXiuuHH35QQECAgoKC1KdPH/3888+SWNOKbNmyZWrVqpUefvhh+fr6qkWLFpozZ47Zz9pWfAUFBVq4cKGefPJJWSwW1rQMUfw7mN9//12FhYXy8/Ozaffz81NWVpadssL1KF63K61pVlaWXF1d5e3tfdkY2JdhGHruued01113KSwsTBJrW5Ht3LlTVapUkZubm55++mktWbJEoaGhrGkFlpiYqO+++04TJ04s0ce6VkytW7fWRx99pK+++kpz5sxRVlaW2rZtq2PHjrGmFdjPP/+s9957T8HBwfrqq6/09NNPa/jw4froo48k8fvqCJYuXaoTJ06oX79+kljTsuRs7wRQPiwWi817wzBKtKFiKc2asu43j6FDh2rHjh3auHFjiT7WtuIJCQlRenq6Tpw4ocWLF6tv377asGGD2c+aViyHDh3Ss88+q+TkZFWuXPmycaxrxdK1a1fzn5s0aaLw8HDVr19f8+fPV5s2bSSxphVRUVGRWrVqpQkTJkiSWrRood27d+u9997T3/72NzOOta245s6dq65duyogIMCmnTW9fuz8O5gaNWrIycmpxF+4srOzS/y1DBVD8Z2Jr7Sm/v7+KigoUE5OzmVjYD/Dhg3TsmXLtG7dOtWuXdtsZ20rLldXVzVo0ECtWrXSxIkT1axZM7311lusaQWVlpam7OxstWzZUs7OznJ2dtaGDRv09ttvy9nZ2VwX1rVi8/T0VJMmTfTDDz/wu1qB1apVS6GhoTZtjRo1Mm9szdpWbAcPHtSaNWv01FNPmW2sadmh+Hcwrq6uatmypXmHzGKrV69W27Zt7ZQVrkdQUJD8/f1t1rSgoEAbNmww17Rly5ZycXGxicnMzNSuXbtYdzsyDENDhw7VF198obVr1yooKMimn7V1HIZhKD8/nzWtoCIiIrRz506lp6ebr1atWumxxx5Tenq6br31VtbVAeTn52vv3r2qVasWv6sVWLt27Uo8Nvf7779X3bp1JfHf1opu3rx58vX1Vffu3c021rQM3eg7DKL8JSYmGi4uLsbcuXONPXv2GHFxcYanp6fxyy+/2Ds1XMbJkyeN7du3G9u3bzckGdOnTze2b99uHDx40DAMw3jjjTcMq9VqfPHFF8bOnTuNRx991KhVq5aRl5dnjvH0008btWvXNtasWWN89913xr333ms0a9bMuHDhgr0O63/eM888Y1itVmP9+vVGZmam+Tpz5owZw9pWPGPGjDG++eYb48CBA8aOHTuMF154wahUqZKRnJxsGAZr6ij+fLd/w2BdK6KRI0ca69evN37++WcjNTXViI6ONry8vMz/H2JNK6YtW7YYzs7Oxuuvv2788MMPxqJFiwwPDw9j4cKFZgxrWzEVFhYaderUMUaPHl2ijzUtGxT/Durdd9816tata7i6uhq33367+Wgx3JzWrVtnSCrx6tu3r2EYfzy25uWXXzb8/f0NNzc345577jF27txpM8bZs2eNoUOHGtWrVzfc3d2N6OhoIyMjww5Hg2KXWlNJxrx588wY1rbiefLJJ81/v9asWdOIiIgwC3/DYE0dxcXFP+ta8TzyyCNGrVq1DBcXFyMgIMB44IEHjN27d5v9rGnF9eWXXxphYWGGm5ubcdtttxmzZ8+26WdtK6avvvrKkGTs37+/RB9rWjYshmEYdjnlAAAAAAAA3BBc8w8AAAAAgIOj+AcAAAAAwMFR/AMAAAAA4OAo/gEAAAAAcHAU/wAAAAAAODiKfwAAAAAAHBzFPwAAAAAADo7iHwAAAAAAB0fxDwAATP369VOvXr3KfNysrCx17txZnp6eqlatWpmPDwAAroziHwCAG6y8Cuxr8csvv8hisSg9Pf2GzDdjxgxlZmYqPT1d33///Q2Z82Lr16+XxWLRiRMn7DI/AAD25GzvBAAAgOP76aef1LJlSwUHB9s7FQAA/iex8w8AwE1mz5496tatm6pUqSI/Pz/Fxsbq999/N/s7dOig4cOHa9SoUapevbr8/f01btw4mzH27dunu+66S5UrV1ZoaKjWrFkji8WipUuXSpKCgoIkSS1atJDFYlGHDh1sPj916lTVqlVLPj4+GjJkiM6fP3/FnN977z3Vr19frq6uCgkJ0YIFC8y+evXqafHixfroo49ksVjUr1+/S46xfv163XnnnealAe3atdPBgwfN/i+//FItW7ZU5cqVdeutt2r8+PG6cOGC2W+xWPTPf/5T999/vzw8PBQcHKxly5ZJ+uNMh44dO0qSvL29bfIwDEOTJ0/WrbfeKnd3dzVr1kyff/65TV4Wi0Vff/21WrVqJQ8PD7Vt21b79++3yX/ZsmVq1aqVKleurBo1auiBBx4w+woKCjRq1Cjdcsst8vT0VOvWrbV+/Xqz/+DBg+rRo4e8vb3l6empxo0ba+XKlVf8zgEAuBYU/wAA3EQyMzPVvn17NW/eXNu2bVNSUpKOHDmi3r1728TNnz9fnp6e2rx5syZPnqxXXnlFq1evliQVFRWpV69e8vDw0ObNmzV79myNHTvW5vNbtmyRJK1Zs0aZmZn64osvzL5169bpp59+0rp16zR//nwlJCQoISHhsjkvWbJEzz77rEaOHKldu3Zp0KBBeuKJJ7Ru3TpJ0tatW9WlSxf17t1bmZmZeuutt0qMceHCBfXq1Uvt27fXjh07lJKSooEDB8pisUiSvvrqKz3++OMaPny49uzZow8++EAJCQl6/fXXbcYZP368evfurR07dqhbt2567LHHdPz4cQUGBmrx4sWSpP3799vk8eKLL2revHl67733tHv3bo0YMUKPP/64NmzYYDP22LFjNW3aNG3btk3Ozs568sknzb4VK1bogQceUPfu3bV9+3bzDwXFnnjiCf3nP/9RYmKiduzYoYcfflhdunTRDz/8IEkaMmSI8vPz9c0332jnzp2aNGmSqlSpctnvHACAa2YAAIAbqm/fvsZ99913yb5//OMfRmRkpE3boUOHDEnG/v37DcMwjPbt2xt33XWXTcwdd9xhjB492jAMw1i1apXh7OxsZGZmmv2rV682JBlLliwxDMMwDhw4YEgytm/fXiK3unXrGhcuXDDbHn74YeORRx657PG0bdvWGDBggE3bww8/bHTr1s18f9999xl9+/a97BjHjh0zJBnr16+/ZP/dd99tTJgwwaZtwYIFRq1atcz3kowXX3zRfH/q1CnDYrEYq1atMgzDMNatW2dIMnJycmxiKleubGzatMlm7P79+xuPPvqozefWrFlj9q9YscKQZJw9e9YwDMMIDw83HnvssUvm/uOPPxoWi8X49ddfbdojIiKMMWPGGIZhGE2aNDHGjRt3yc8DAFAWuOYfAICbSFpamtatW3fJXd+ffvpJDRs2lCQ1bdrUpq9WrVrKzs6W9MfOdmBgoPz9/c3+O++886pzaNy4sZycnGzG3rlz52Xj9+7dq4EDB9q0tWvX7pI7/JdTvXp19evXT1FRUercubM6deqk3r17q1atWpL++F62bt1qs9NfWFioc+fO6cyZM/Lw8JBk+714enrKy8vL/F4uZc+ePTp37pw6d+5s015QUKAWLVrYtP157OK8srOzVadOHaWnp2vAgAGXnOO7776TYRjm2hXLz8+Xj4+PJGn48OF65plnlJycrE6dOunBBx8sscYAAFwPin8AAG4iRUVF6tGjhyZNmlSir7jglCQXFxebPovFoqKiIkl/XMNefLp8aVxp7Mu5eL7S5DBv3jwNHz5cSUlJ+vTTT/Xiiy9q9erVatOmjYqKijR+/Hib6+iLVa5cudS5F/etWLFCt9xyi02fm5ubzfs/j118bMWfd3d3v+IcTk5OSktLs/mjiiTzjzxPPfWUoqKitGLFCiUnJ2vixImaNm2ahg0bdtlxAQC4FhT/AADcRG6//XYtXrxY9erVk7Nz6f4zfdtttykjI0NHjhyRn5+fpD+uu/8zV1dXSX/snl+vRo0aaePGjfrb3/5mtm3atEmNGjW65rFatGihFi1aaMyYMQoPD9fHH3+sNm3a6Pbbb9f+/fvVoEGDUud5qWMODQ2Vm5ubMjIy1L59+1KP3bRpU3399dd64oknSvS1aNFChYWFys7O1t13333ZMQIDA/X000/r6aef1pgxYzRnzhyKfwBAmaH4BwDADnJzc5Wenm7TVr16dQ0ZMkRz5szRo48+qr///e+qUaOGfvzxRyUmJmrOnDkldo4vpXPnzqpfv7769u2ryZMn6+TJk+YN/4p3rH19feXu7q6kpCTVrl1blStXltVqLdWx/P3vf1fv3r11++23KyIiQl9++aW++OILrVmz5qrHOHDggGbPnq2ePXsqICBA+/fv1/fff2/+QeGll15SdHS0AgMD9fDDD6tSpUrasWOHdu7cqddee+2q5qhbt64sFouWL1+ubt26yd3dXV5eXoqPj9eIESNUVFSku+66S3l5edq0aZOqVKmivn37XtXYL7/8siIiIlS/fn316dNHFy5c0KpVqzRq1Cg1bNhQjz32mP72t79p2rRpatGihX7//XetXbtWTZo0Ubdu3RQXF6euXbuqYcOGysnJ0dq1a0v1xxMAAC6Hu/0DAGAH69evN3e5i18vvfSSAgIC9J///EeFhYWKiopSWFiYnn32WVmtVlWqdHX/2XZyctLSpUt16tQp3XHHHXrqqaf04osvSvr/p8g7Ozvr7bff1gcffKCAgADdd999pT6WXr166a233tKUKVPUuHFjffDBB5o3b16JxwdeiYeHh/bt26cHH3xQDRs21MCBAzV06FANGjRIkhQVFaXly5dr9erVuuOOO9SmTRtNnz5ddevWveo5brnlFo0fP17PP/+8/Pz8NHToUEnSq6++qpdeekkTJ05Uo0aNFBUVpS+//NJ8HOLV6NChg/71r39p2bJlat68ue69915t3rzZ7J83b57+9re/aeTIkQoJCVHPnj21efNmBQYGSvrjbIQhQ4aoUaNG6tKli0JCQjRr1qyrnh8AgL9iMQzDsHcSAACgfP3nP//RXXfdpR9//FH169e3dzoAAOAGo/gHAMABLVmyRFWqVFFwcLB+/PFHPfvss/L29tbGjRvtnRoAALADrvkHAMABnTx5UqNGjdKhQ4dUo0YNderUSdOmTbN3WgAAwE7Y+QcAAAAAwMFxwz8AAAAAABwcxT8AAAAAAA6O4h8AAAAAAAdH8Q8AAAAAgIOj+AcAAAAAwMFR/AMAAAAA4OAo/gEAAAAAcHAU/wAAAAAAOLj/BzZzu0m3AlktAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist([len(sentence) for sentence in english_sentences], label=\"English\", alpha=0.5)\n",
    "plt.hist([len(sentence) for sentence in kannada_sentences], label=\"Kannada\", alpha=0.5)\n",
    "plt.title(\"Distribution of the length of sentences\", fontsize=12)\n",
    "plt.xlabel(\"Length of sentences\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish this, we will use sentences in the 97th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length in English: 179\n",
      "97th percentile length in Kannada: 172\n"
     ]
    }
   ],
   "source": [
    "PERCENTILE = 97\n",
    "print(\n",
    "    f\"{PERCENTILE}th percentile length in English: {np.percentile([len(sentence) for sentence in english_sentences], PERCENTILE):.0f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{PERCENTILE}th percentile length in Kannada: {np.percentile([len(sentence) for sentence in kannada_sentences], PERCENTILE):.0f}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the maximum sentence lengths for English and Kannada are pretty close. We can comfortably pick a `max_sequence_length` of 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English sentences: 100000\n",
      "Number of Kannada sentences: 100000\n",
      "Number of valid sentences: 81947\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "\n",
    "def is_valid_tokens(sentence: str, vocab: list[str]) -> bool:\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def is_valid_length(sentence: str, max_sequence_length: int) -> bool:\n",
    "    return (\n",
    "        len(list(sentence)) <= max_sequence_length - 1\n",
    "    )  # need to re-add the end token so leaving 1 space\n",
    "\n",
    "\n",
    "valid_sentence_indices = []\n",
    "for index in range(len(english_sentences)):\n",
    "    english_sentence, kannada_sentence = (\n",
    "        english_sentences[index],\n",
    "        kannada_sentences[index],\n",
    "    )\n",
    "    if (\n",
    "        is_valid_tokens(english_sentence, english_vocabulary)\n",
    "        and is_valid_length(english_sentence, max_sequence_length)\n",
    "        and is_valid_tokens(kannada_sentence, kannada_vocabulary)\n",
    "        and is_valid_length(kannada_sentence, max_sequence_length)\n",
    "    ):\n",
    "        valid_sentence_indices.append(index)\n",
    "\n",
    "\n",
    "print(f\"Number of English sentences: {len(english_sentences)}\")\n",
    "print(f\"Number of Kannada sentences: {len(kannada_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = [english_sentences[i] for i in valid_sentence_indices]\n",
    "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hes a scientist.',\n",
       " \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
       " '8 lakh crore have been looted.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.',\n",
       " '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"',\n",
       " 'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, english_sentences: list[str], kannada_sentences: list[str]):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.kannada_sentences = kannada_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.kannada_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81947"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TextDataset(english_sentences, kannada_sentences)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hes a scientist.', 'ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching Sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, let's assume our batch size is 3. To explain why we're batching, let's say we take just one input English sentence and one Kannada translation as just the batch size (in this case, batch size would simply be 1 which is essentially no batching). So if we were to pass one English sentence and one Kannada sentence during training, we'll get some output loss and we're going to perform back propagation to update all of these millions of parameters in order to now, get a new state. Then, we will repeat this again with another input English sentence and Kannada sentence. Updating each and every single parameter for just a single input example is computationally expensive and takes a very long time. The loss steps will also be very unstable.\n",
    "\n",
    "Therefore, in order to speed up the training, we parallelize passing information into the network by batching up the examples. In our case, we chose 3 examples that make up our batch each time information is fed into the network. After the loss for all three examples have been computed, only then we perform back propagation and update the parameters. So, we're essentially updating once for every three inputs. We can increase the batch size to decrease the number of times the entire network is going to be updated and this will speed up training and hence, for many machine learning algorithms, we use mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hes a scientist.', \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\", '8 lakh crore have been looted.'), ('ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.', '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"', 'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.')]\n",
      "[('I read a lot into this as well.', 'How did mankind come under Satans rival sovereignty?', 'And then I became Prime Minister.'), ('ಇದರ ಬಗ್ಗೆ ನಾನೂ ಸಾಕಷ್ಟು ಓದಿದ್ದೇನೆ.', 'ಮಾನವಕುಲವು ಸೈತಾನನ ಆಳಿಕೆಯ ಕೆಳಗೆ ಬಂದದ್ದು ಹೇಗೆ?', 'ನಂತರ ಪ್ರಧಾನಿ ಕೂಡ ಆಗುತ್ತೇನೆ.')]\n",
      "[('What about corruption?', '\"\"\"The shooting of the film is 90 percent done.\"', 'the Special Statute'), ('ಭ್ರಷ್ಟಾಚಾರ ಏಕಿದೆ?', 'ಆ ಚಿತ್ರದ ಶೇ 90ರಷ್ಟು ಚಿತ್ರೀಕರಣವೂ ಈಗಾಗಲೇ ಮುಗಿದು ಹೋಗಿದೆ.', 'ವಿಶೇಷ ಕಾನೂನು')]\n",
      "[('\"Then the king said to Ittai the Gittite, \"\"Why do you also go with us? Return, and stay with the king. for you are a foreigner, and also an exile. Return to your own place.\"', 'What happened at the UN General Assembly?', 'The meeting was attended by Prime Minister Narendra Modi, Home Minister Amit Shah and Defence Minister Rajnath Singh, among others.'), ('ಆಗ ಅರಸನು ಗಿತ್ತೀಯನಾದ ಇತ್ತೈಯನ್ನು ನೋಡಿ--ನೀನು ನಮ್ಮ ಸಂಗಡ ಬರುವದು ಯಾಕೆ? ನಿನ್ನ ಸ್ಥಳಕ್ಕೆ ಹಿಂದಿರುಗಿ ಹೋಗಿ ಅರಸನ ಸಂಗಡ ಇರು. ಯಾಕಂದರೆ ನೀನು ಸೆರೆಹಿಡಿಯಲ್ಪಟ್ಟವನಾದ ಅನ್ಯದೇಶದವನು.', 'ವಿಶ್ವ ಗೋ ಸಮ್ಮೇಳನದ ಅಂಗಳದಲ್ಲಿ ಏನೇನು ನಡೆದಿದೆ?', 'ಪ್ರಧಾನ ಮಂತ್ರಿ ನರೇಂದ್ರ ಮೋದಿ, ರಕ್ಷಣಾ ಸಚಿವ ರಾಜನಾಥ್ ಸಿಂಗ್ ಮತ್ತು ಕೇಂದ್ರ ಗೃಹ ಸಚಿವ ಅಮಿತ್ ಷಾ ಅವರು ಮಸೂದೆಯ ಬಗ್ಗೆ ಸಾರ್ವಜನಿಕ ಚರ್ಚೆ ಗೆ ಬರುವಂತೆ ಸಂಘ ಸವಾಲು ಹಾಕಿದೆ.')]\n",
      "[('It has been under discussion for a long time.', 'Buses cannot get there.', 'Why then this tradition was not thought of?'), ('ಎಂಬುದು ಬಹಳ ದೀರ್ಘ ಕಾಲದಿಂದಲೂ ಚರ್ಚಿತವಾಗುತ್ತಿರುವ ವಿಷಯ.', 'ಇಲ್ಲಿಗೆ ಬರಲು ಬಸ್ ಸೌಕರ್ಯವೂ ಇಲ್ಲ.', 'ಆ ಪರಂಪರೆ ಯಾಕೆ ಮುನ್ನೆಲೆಗೆ ಬರಲಿಲ್ಲ?')]\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(train_loader):\n",
    "    print(batch)\n",
    "    if batch_num > 3:  # print only first 4 batches\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character to Number Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, is tokenization. We have sentences and so, we need to convert these into numbers because computers don't understand text and they only understand numbers. The `tokenize` function below takes in a sentence, a language to index which contains the characters to numbers embedding and an optional start and end token. If we choose to have a start and end token, we will prepend and append the tokens respectively to the sentence. In most cases, we will also append padding tokens to sentences until they match the maximum sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(\n",
    "    sentence: str,\n",
    "    language_to_index: dict[str, int],\n",
    "    start_token: bool = True,\n",
    "    end_token: bool = True,\n",
    ") -> torch.tensor:\n",
    "    sentence_word_indices = [language_to_index[char] for char in list(sentence)]\n",
    "    if start_token:\n",
    "        sentence_word_indices.insert(0, language_to_index[START_TOKEN])\n",
    "    if end_token:\n",
    "        sentence_word_indices.append(language_to_index[END_TOKEN])\n",
    "    # Add padding tokens\n",
    "    for _ in range(len(sentence_word_indices), max_sequence_length):\n",
    "        sentence_word_indices.append(language_to_index[PADDING_TOKEN])\n",
    "    return torch.tensor(sentence_word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It has been under discussion for a long time.',\n",
       "  'Buses cannot get there.',\n",
       "  'Why then this tradition was not thought of?'),\n",
       " ('ಎಂಬುದು ಬಹಳ ದೀರ್ಘ ಕಾಲದಿಂದಲೂ ಚರ್ಚಿತವಾಗುತ್ತಿರುವ ವಿಷಯ.',\n",
       "  'ಇಲ್ಲಿಗೆ ಬರಲು ಬಸ್ ಸೌಕರ್ಯವೂ ಇಲ್ಲ.',\n",
       "  'ಆ ಪರಂಪರೆ ಯಾಕೆ ಮುನ್ನೆಲೆಗೆ ಬರಲಿಲ್ಲ?')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every sentence in the batch, we will call the `tokenize` function. For the English sentences, we don't have to use start and end tokens because we are passing every word into the network simultaneously anyways — we will have the entire English sentence.\n",
    "\n",
    "As for the Kannada sentences, we require the start and end tokens because during the generation phase, the network is not going to have any kind of word to start with. Therefore, we have to inject something into the model and that will be the start token. Similarly, we pass in the end token to tell the network where the sentence ends. After that, it's just padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 200])\n",
      "torch.Size([3, 200])\n"
     ]
    }
   ],
   "source": [
    "english_tokenized, kannada_tokenized = [], []\n",
    "for sentence_num in range(BATCH_SIZE):\n",
    "    english_sentence, kannada_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
    "    english_tokenized.append(\n",
    "        tokenize(english_sentence, english_to_index, start_token=False, end_token=False)\n",
    "    )\n",
    "    kannada_tokenized.append(\n",
    "        tokenize(kannada_sentence, kannada_to_index, start_token=True, end_token=True)\n",
    "    )\n",
    "\n",
    "english_tokenized = torch.stack(english_tokenized, dim=0)\n",
    "kannada_tokenized = torch.stack(kannada_tokenized, dim=0)\n",
    "\n",
    "print(english_tokenized.shape)\n",
    "print(kannada_tokenized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[41., 84.,  1., 72., 65., 83.,  1., 66., 69., 69., 78.,  1., 85., 78.,\n",
       "         68., 69., 82.,  1., 68., 73., 83., 67., 85., 83., 83., 73., 79., 78.,\n",
       "          1., 70., 79., 82.,  1., 65.,  1., 76., 79., 78., 71.,  1., 84., 73.,\n",
       "         77., 69., 15., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96.],\n",
       "        [34., 85., 83., 69., 83.,  1., 67., 65., 78., 78., 79., 84.,  1., 71.,\n",
       "         69., 84.,  1., 84., 72., 69., 82., 69., 15., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96.],\n",
       "        [55., 72., 89.,  1., 84., 72., 69., 78.,  1., 84., 72., 73., 83.,  1.,\n",
       "         84., 82., 65., 68., 73., 84., 73., 79., 78.,  1., 87., 65., 83.,  1.,\n",
       "         78., 79., 84.,  1., 84., 72., 79., 85., 71., 72., 84.,  1., 79., 70.,\n",
       "         31., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96., 96.,\n",
       "         96., 96., 96., 96.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that we don't really need a typical type of masking for the encoder part. The only kind of masking the encoder requires is a padding mask. This padding mask simply tells the encoder not look at the padding tokens when the network is computing the loss function and updating the gradient weights. The padding tokens mean nothing. Therefore, we need a padding mask interjected in the encoder within the multi-head attention mechanism.\n",
    "\n",
    "With the decoder, it requires a mass multi-headed attention mask. During inference, the decoder cannot look forward to what tokens should be generated. That's a form of data leakage if it were able to look ahead and we cannot have that. Therefore, what we do is we mask all the tokens that comes after a character. We are telling the network that we have no context of future words and the only context we can derive from are characters that came before. On top of this, we also have a padding mask (like in the encoder) that masks the padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = 1e-9\n",
    "\n",
    "\n",
    "def create_masks(english_batch, kannada_batch):\n",
    "    assert len(english_batch) == len(kannada_batch)\n",
    "    num_sentences = len(english_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length], True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full(\n",
    "        [num_sentences, max_sequence_length, max_sequence_length], False\n",
    "    )\n",
    "    decoder_padding_mask_self_attention = torch.full(\n",
    "        [num_sentences, max_sequence_length, max_sequence_length], False\n",
    "    )\n",
    "    decoder_padding_mask_cross_attention = torch.full(\n",
    "        [num_sentences, max_sequence_length, max_sequence_length], False\n",
    "    )\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "        english_sentence_len, kannada_sentence_len = len(english_batch[idx]), len(\n",
    "            kannada_batch[idx]\n",
    "        )\n",
    "        english_chars_to_padding_mask = np.arange(\n",
    "            english_sentence_len + 1, max_sequence_length\n",
    "        )\n",
    "        kannada_chars_to_padding_mask = np.arange(\n",
    "            kannada_sentence_len + 1, max_sequence_length\n",
    "        )\n",
    "        # encoder padding mask\n",
    "        encoder_padding_mask[idx, :, english_chars_to_padding_mask] = True\n",
    "        encoder_padding_mask[idx, english_chars_to_padding_mask, :] = True\n",
    "        # decoder padding mask for self-attention\n",
    "        decoder_padding_mask_self_attention[\n",
    "            idx, :, kannada_chars_to_padding_mask\n",
    "        ] = True\n",
    "        decoder_padding_mask_self_attention[\n",
    "            idx, kannada_chars_to_padding_mask, :\n",
    "        ] = True\n",
    "        # decoder padding mask for cross attention\n",
    "        decoder_padding_mask_cross_attention[\n",
    "            idx, :, kannada_chars_to_padding_mask\n",
    "        ] = True\n",
    "        decoder_padding_mask_cross_attention[\n",
    "            idx, kannada_chars_to_padding_mask, :\n",
    "        ] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    # look ahead mask prevents it from looking ahead at future words\n",
    "    decoder_self_attention_mask = torch.where(\n",
    "        look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0\n",
    "    )\n",
    "    decoder_cross_attention_mask = torch.where(\n",
    "        decoder_padding_mask_cross_attention, NEG_INFTY, 0\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :10, :10]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        encoder_self_attention_mask,\n",
    "        decoder_self_attention_mask,\n",
    "        decoder_cross_attention_mask,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `create_masks` function above, zeros are for values that are not masked and negative large numbers are to indicate masking. This is because we will be using the $\\text{softmax}$ function which outputs a 1 for zeros and 0 for negative infinity. In this case, it will result in a very small value  which is close to zero because we are using a large negative number instead.\n",
    "\n",
    "The reason why we are not using negative infinity is because we may end up with cases where entire rows are just zeros. This will lead to numerical instability which makes the network untrainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "decoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[0.0000e+00, 1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09,\n",
      "         1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09,\n",
      "         1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-09, 1.0000e-09, 1.0000e-09,\n",
      "         1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-09, 1.0000e-09,\n",
      "         1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-09,\n",
      "         1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e-09, 1.0000e-09, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e-09, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e-09, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "decoder_cross_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    encoder_self_attention_mask,\n",
    "    decoder_self_attention_mask,\n",
    "    decoder_cross_attention_mask,\n",
    ") = create_masks(batch[0], batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEmbedding(nn.Module):\n",
    "    \"\"\"For a given sentence, create an embedding.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_sequence_length: int,\n",
    "        d_model: int,\n",
    "        language_to_idx: dict[str, int],\n",
    "        START_TOKEN: bool,\n",
    "        END_TOKEN: bool,\n",
    "        PADDING_TOKEN: bool,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(language_to_idx)\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
    "        self.language_to_idx = language_to_idx\n",
    "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.START_TOKEN = START_TOKEN\n",
    "        self.END_TOKEN = END_TOKEN\n",
    "        self.PADDING_TOKEN = PADDING_TOKEN\n",
    "\n",
    "    def batch_tokenize(\n",
    "        self, batch: torch.tensor, start_token: bool = True, end_token: bool = True\n",
    "    ) -> torch.tensor:\n",
    "        def tokenize(sentence: str, start_token: bool = True, end_token: bool = True):\n",
    "            sentence_word_indices = [\n",
    "                self.language_to_idx[char] for char in list(sentence)\n",
    "            ]\n",
    "            if start_token:\n",
    "                sentence_word_indices.insert(0, self.language_to_idx[self.START_TOKEN])\n",
    "            if end_token:\n",
    "                sentence_word_indices.append(self.language_to_idx[self.END_TOKEN])\n",
    "            # Add padding tokens\n",
    "            for _ in range(len(sentence_word_indices), self.max_sequence_length):\n",
    "                sentence_word_indices.append(self.language_to_idx[self.PADDING_TOKEN])\n",
    "            return torch.tensor(sentence_word_indices)\n",
    "\n",
    "        tokenized = []\n",
    "        for sentence_num in range(len(batch)):\n",
    "            tokenized.append(tokenize(batch[sentence_num], start_token, end_token))\n",
    "        tokenized = torch.stack(tokenized, dim=0)\n",
    "        return tokenized.to(get_device())\n",
    "\n",
    "    def forward(self, x, start_token: bool = True, end_token: bool = True):\n",
    "        x = self.batch_tokenize(x, start_token, end_token)\n",
    "        x = self.embedding(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x += pos\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
